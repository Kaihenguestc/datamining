https://www.kesci.com/home/project/5dc4f34cad7dde00367e0f50
# 查看当前挂载的数据集目录
!ls /home/kesci/input/
# 查看个人持久化工作区文件
!ls /home/kesci/work/
# 查看当前kernerl下的package
!pip list --format=columns
# 显示cell运行时长
%load_ext klab-autotime
#导入必要的包
import numpy as np
import sklearn
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler
from sklearn import feature_selection
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.model_selection import GridSearchCV,RandomizedSearchCV
from sklearn.metrics import roc_auc_score, roc_curve
from xgboost.sklearn import XGBClassifier
from sklearn.model_selection import cross_val_score
import seaborn as sns
import lightgbm as lgb
import math
import warnings
warnings.filterwarnings("ignore")
#导入文件并进行数据处理
def readFile(fileName):
    fileObject = open('/home/kesci/input/DC_new3148/' + fileName, 'r')
    newList = []
    for line in fileObject:
        line = line.strip('\n')
        newList.append(line.split(','))
    data = [i[1:] for i in newList[1:]]
    pdData = pd.DataFrame(data, index=[i[0] for i in newList[1:]], columns=newList[0][1:])
    fileObject.close()
    return pdData

train_pdData=readFile('train_pdData.csv')
test_pdData=readFile('test_pdData.csv')
for i in train_pdData.columns:
    if i!='y':
        train_pdData[i]=train_pdData[i].astype('float')
        test_pdData[i]=test_pdData[i].astype('float')
    else:
        train_pdData[i] = train_pdData[i].astype('float')
数据相关的可视化
可视化各个类别属性的关联
plt.figure(figsize=(36,30))
sns.set()
sns.pairplot(train_pdData[['loanProduct','gender','basicLevel','highestEdu','weekday','job','edu','x_34','x_33','lmt','x_45','x_46','setupHour','y']],hue="y")  类列  
plt.show()
观察value_count特征是否优于原特征（针对类别特征 ）
这里分析结果表明改变job,weekday,loanProduct的编码（主要改变原有的编码顺序）是可提升的，但反馈到A榜下降
cate_list=['loanProduct','basicLevel','weekday','job','edu','lmt','setupHour']
#cate_list=['loanProduct']
pout_train=train_pdData.copy()
target=train_pdData[train_pdData['isNew']==1]['y']
def count_(pout_train,i):
    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=666)
    oof = np.zeros(len(pout_train))

    for  fold_, (trn_idx, val_idx) in enumerate(folds.split(pout_train[i].values, target)):
        print("Fold {}".format(fold_))

        trn_data, trn_label = pout_train[i].iloc[trn_idx], target[trn_idx]
        val_data,val_label= pout_train[i].iloc[val_idx], target[val_idx]

        trn_data,val_data=trn_data.values,val_data.values
        trn_label,val_label=trn_label.values,val_label.values
        clf = XGBClassifier(max_depth=4,gamma=0,n_estimators=50,eta=0.1,min_child_weight=1)

        view_list=[(trn_data,trn_label),(val_data,val_label)]
        clf.fit(trn_data,trn_label,eval_set=view_list,eval_metric='auc',early_stopping_rounds=200)
        y_val, y_val_pred = val_label, clf.predict_proba(val_data)[:,1]
        auc_score=roc_auc_score(y_val, y_val_pred)
        print(auc_score)
        print('-------------------------------------------------------------------------------------------------')
        oof[val_idx] = clf.predict_proba(pout_train[i].values[val_idx])[:,1]
    print("CV score: {:<8.5f}".format(roc_auc_score(target, oof)))
    return roc_auc_score(target, oof)
count_list=[]
for i in  cate_list:
    pout_train[i+'_'+'count']=pout_train.groupby(i)[i].transform('count')
    score=count_(pout_train[pout_train['isNew']==1],[i])
    score_count=count_(pout_train[pout_train['isNew']==1],[i,i+'_'+'count'])
    count_list.append([score,score_count,score_count-score])
print(pd.DataFrame(data=count_list,index=cate_list,columns=['score','score_count','improve']))
#查看样本的缺失值的分布
def queshi(df):
    queshi_list=[]
    for i in range(df.shape[0]):
        queshi_list.append(df.iloc[i].values.tolist().count(-999))
    queshi_list.sort()
    plt.figure(figsize=(20,20))
    plt.scatter(range(len(queshi_list)),queshi_list)
    plt.show()
    
queshi(train_pdData)
queshi(test_pdData)
#结果表明在训练集，测试集在训练样本上的缺失值分布相同。


#编码处理，处理身份证，银行卡，居住地的特征编码，挖掘隐藏的信息
#提取每一位的编码信息
def bian_ma(x,i):
    y=-999
    if x!=0 or x!=-999:
        y=x%(10**i)//(10**(i-1))
    else:
        y=-999
    return y
    
#对身份证信息进行特征编码处理
for i in range(4):
    train_pdData['residentAddr_'+str(i+1)]=train_pdData['residentAddr'].map(lambda x: bian_ma(x,i))
    test_pdData['residentAddr_'+str(i+1)]=test_pdData['residentAddr'].map(lambda x: bian_ma(x,i))
#特征构建
#处理is_old中的居住地的偏差问题。
#经数据的EDA分析发现is_New==0的数据中的residentAddr数据要比dist高300000。
#修正is_New==0的数据中的residentAddr字段。减少is_new=0与1分布之间的差异
Addr_list=[]
for i in range(len(train_pdData)):
    if train_pdData['isNew'][i]==0 and train_pdData['residentAddr'][i]!=-999:
        Addr_list.append(train_pdData['residentAddr'][i]-300000)
    else:
        Addr_list.append(train_pdData['residentAddr'][i])
        
train_pdData['residentAddr']=np.array(Addr_list)

#关于银行卡的信息的特征构建
def bank_bin(x):
    y=-999
    if x!=0 or x!=-999:
        y=int(x/1000)
    else:
        y=-999
    return y
train_pdData['bank_bin']=train_pdData['bankCard'].map(bank_bin)
test_pdData['bank_bin']=test_pdData['bankCard'].map(bank_bin)
def card_sign(x):
    y=-999
    if x!=0 or x!=-999:
        y=x-1000*(int(x/1000))
    else:
        y=-999
    return y
train_pdData['card_sign']=train_pdData['bankCard'].map(card_sign)
test_pdData['card_sign']=test_pdData['bankCard'].map(card_sign)

train_pdData['cert_id_sign']=train_pdData['certId'].map(lambda x:x-(x//10000)*10000)
test_pdData['cert_id_sign']=test_pdData['certId'].map(lambda x:x-(x//10000)*10000)

train_pdData['cert_id_level']=train_pdData['certId'].map(lambda x:(x-(x//100000)*100000)//10000)
test_pdData['cert_id_level']=test_pdData['certId'].map(lambda x:(x-(x//100000)*100000)//10000)

#构造交叉特征
train_pdData['certId_dist']=train_pdData['certId']-train_pdData['dist']
test_pdData['certId_dist']=test_pdData['certId']-test_pdData['dist']

train_pdData['resident_certId']=train_pdData['certId']-train_pdData['residentAddr']
test_pdData['resident_certId']=test_pdData['certId']-test_pdData['residentAddr']

train_pdData["certStopDt"+"certBeginDt"] = train_pdData["certValidStop"] - train_pdData["certValidBegin"]
test_pdData["certStopDt"+"certBeginDt"] = test_pdData["certValidStop"] - test_pdData["certValidBegin"]

train_pdData['edu_high_dist']=train_pdData['highestEdu'].values-train_pdData['edu'].values
test_pdData['edu_high_dist']=test_pdData['highestEdu'].values-test_pdData['edu'].values

#构造时序特征
train_pdData['time']=train_pdData['weekday'].values*24+train_pdData['setupHour'].values
test_pdData['time']=test_pdData['weekday'].values*24+test_pdData['setupHour'].values

#缺失特征的构建
#构建缺失值特征在线下得到提升，但是A榜线上下降
def queshi_feature(df):
    queshi_list=[]
    for i in range(df.shape[0]):
        queshi_list.append(df.iloc[i].values.tolist().count(-999))
    return np.array(queshi_list)
    
#train_pdData['queshi']=queshi_feature(train_pdData)
#test_pdData['queshi']=queshi_feature(test_pdData)
#对缺失值进行均值填补
for col in test_pdData.columns:
    if np.min(train_pdData[col].values)==-999 and col not in ['highestEdu']:
        mean_num=np.mean([i for i in np.vstack((train_pdData[col].values.reshape(-1,1), test_pdData[col].values.reshape(-1,1))) if i!=-999])
        train_pdData[col].replace(-999,mean_num,inplace=True)
        test_pdData[col].replace(-999,mean_num,inplace=True)
    if col in ['highestEdu']:
        train_pdData[col].replace(-999,999,inplace=True)
        test_pdData[col].replace(-999,999, inplace=True)
#数据的分布可视化
def distribute_visual(train_df, test_df):
    colums_name = test_df.columns
    train0_df_turple, train1_df_turple = train_df.groupby('y')
    train0_df, train1_df = train0_df_turple[1], train1_df_turple[1]

    sns.set_style('whitegrid')
    # plt.figure()
    figure_length = len(colums_name)  # 绘制长为特征数目的大图，每行包括两个图
    # fig,ax=plt.subplots(figure_length,2,figsize=(8,40))
    for feature_name_index in range(len(colums_name)):
        feature_name = colums_name[feature_name_index]
        plt.figure(figsize=(10,250))
        plt.subplot(figure_length, 2, 2 * feature_name_index + 1)
        sns.distplot(train0_df[feature_name].values.tolist(), hist=True, kde=True, norm_hist=False,
                     rug=False, vertical=False,
                     color='g', label=feature_name + '0', axlabel='x')
        sns.distplot(train1_df[feature_name].values.tolist(), hist=True, kde=True, norm_hist=False,
                     rug=False, vertical=False,
                     color='r', hist_kws={"alpha": 0.1}, label=feature_name + '1', axlabel='x')
        plt.tight_layout()
        plt.legend()
        plt.subplot(figure_length, 2, 2 * feature_name_index + 2)
        sns.distplot(train_df[feature_name].values.tolist(), hist=True, kde=True, norm_hist=False,
                     rug=False, vertical=False,
                     color='g', label=feature_name + '_' + 'train', axlabel='x')
        sns.distplot(test_df[feature_name].values.tolist(), hist=True, kde=True, norm_hist=False,
                     rug=False, vertical=False,
                     color='r', hist_kws={"alpha": 0.5}, label=feature_name + '_' + 'test', axlabel='x')
        plt.tight_layout()
        plt.legend()
        plt.show()
distribute_visual(train_pdData, test_pdData)














































































#类别特征，之后进行onehot
categorical_feature_list=['loanProduct','basicLevel','highestEdu','weekday','job','edu','x_34','x_33']
#对old数据中的数据进行筛选
#EDA发现周六的数据在isNew与isOld上的先验概率差别明显，选择去除周六的数据，在A榜上的提升明显。
train_pdData=pd.concat([train_pdData[(train_pdData['isNew']==0)&(train_pdData['weekday']!=6)],train_pdData[train_pdData['isNew']==1]],axis=0)
#去掉is_New中的周六的数据后的数据的数量
print(train_pdData.shape[0])
110602
#查看isNew,isOld中类别特征的先验概率
for i in ['loanProduct','gender','basicLevel','highestEdu','weekday','job','edu','x_34','x_33','setupHour','lmt']:
    #print(train_pdData[train_pdData['isNew']==1].groupby(i)['y'].apply(lambda x:sum(x)))
    #print(train_pdData[train_pdData['isNew'] == 1].groupby(i)['y'].apply(lambda x: len(x)))
    find_df = train_pdData[train_pdData['isNew'] == 1].groupby(i)['y'].apply(lambda x: sum(x)/len(x)).reset_index()
    find_df.columns = [i, 'ratio']
    find_df['len']=train_pdData[train_pdData['isNew'] == 1].groupby(i)['y'].apply(lambda x:len(x)).tolist()
    find_df['sum']=train_pdData[train_pdData['isNew'] == 1].groupby(i)['y'].apply(lambda x:sum(x)).tolist()
    #print(train_pdData[train_pdData['isNew'] == 0].groupby(i)['y'].apply(lambda x: sum(x)))
    #print(train_pdData[train_pdData['isNew'] == 0].groupby(i)['y'].apply(lambda x: len(x)))
    find_df2 = train_pdData[train_pdData['isNew'] == 0].groupby(i)['y'].apply(lambda x: sum(x)/len(x)).reset_index()
    find_df2.columns = [i, 'ratio']
    find_df2['len']=train_pdData[train_pdData['isNew'] == 0].groupby(i)['y'].apply(lambda x:len(x)).tolist()
    find_df2['sum']=train_pdData[train_pdData['isNew'] == 0].groupby(i)['y'].apply(lambda x:sum(x)).tolist()
    #find_df['len']=find_df['len'].values-find_df2['len2'].values
    print(find_df)
    print(find_df2)
   loanProduct     ratio    len    sum
0          1.0  0.013623  22608  308.0
1          2.0  0.005171  16630   86.0
2          3.0  0.004770   8595   41.0
   loanProduct     ratio    len    sum
0          1.0  0.010154  11719  119.0
1          2.0  0.005930  40473  240.0
2          3.0  0.005105  10577   54.0
   gender     ratio    len    sum
0     1.0  0.011022  11160  123.0
1     2.0  0.008508  36673  312.0
   gender     ratio    len    sum
0     1.0  0.006042  15890   96.0
1     2.0  0.006762  46879  317.0
   basicLevel     ratio    len    sum
0         1.0  0.010267  24740  254.0
1         2.0  0.005644   7441   42.0
2         3.0  0.008889  15637  139.0
3         4.0  0.000000     15    0.0
   basicLevel     ratio    len    sum
0    1.000000  0.005766  15956   92.0
1    1.961579  0.018108   2209   40.0
2    2.000000  0.006289  23532  148.0
3    3.000000  0.006273  21043  132.0
4    4.000000  0.034483     29    1.0
   highestEdu     ratio    len    sum
0        10.0  0.000000     23    0.0
1        20.0  0.009804    204    2.0
2        30.0  0.014344    488    7.0
3        40.0  0.011667    600    7.0
4        50.0  0.000000      2    0.0
5        60.0  0.000000      8    0.0
6        70.0  0.010050    199    2.0
7        99.0  0.006237  12185   76.0
8       999.0  0.009993  34124  341.0
   highestEdu     ratio    len    sum
0        10.0  0.000000      6    0.0
1        20.0  0.000000     74    0.0
2        30.0  0.025806    155    4.0
3        40.0  0.016807    238    4.0
4        70.0  0.032258     62    2.0
5        99.0  0.002497   5606   14.0
6       999.0  0.006869  56628  389.0
   weekday     ratio    len    sum
0      1.0  0.009153   5572   51.0
1      2.0  0.006472   4326   28.0
2      3.0  0.007680   4557   35.0
3      4.0  0.005789   5700   33.0
4      5.0  0.007454  11135   83.0
5      6.0  0.013695  13582  186.0
6      7.0  0.006417   2961   19.0
   weekday     ratio    len   sum
0      1.0  0.007189   9042  65.0
1      2.0  0.007739   9820  76.0
2      3.0  0.006183  12938  80.0
3      4.0  0.006407  12798  82.0
4      5.0  0.005823   9960  58.0
5      7.0  0.006333   8211  52.0
     job     ratio    len    sum
0    1.0  0.010553   3980   42.0
1    2.0  0.001456   4120    6.0
2    3.0  0.008336  17394  145.0
3    4.0  0.011940  14573  174.0
4    5.0  0.008310   3249   27.0
5    6.0  0.007733   2457   19.0
6    7.0  0.013105    992   13.0
7    8.0  0.008629   1043    9.0
8   10.0  0.000000     21    0.0
9   11.0  0.000000      1    0.0
10  12.0  0.000000      1    0.0
11  13.0  0.000000      2    0.0
    job     ratio    len    sum
0   1.0  0.003973   1762    7.0
1   2.0  0.006446   3258   21.0
2   3.0  0.004857   1853    9.0
3   4.0  0.008950   6816   61.0
4   6.0  0.005305    377    2.0
5   7.0  0.008486   1532   13.0
6   8.0  0.000000     20    0.0
7  16.0  0.006363  47151  300.0
         edu     ratio    len    sum
0   0.000000  0.009416  45879  432.0
1   0.765549  0.000000     18    0.0
2  10.000000  0.000000     30    0.0
3  20.000000  0.000000    267    0.0
4  30.000000  0.003106    644    2.0
5  40.000000  0.000000    716    0.0
6  47.000000  0.000000      2    0.0
7  60.000000  0.000000     50    0.0
8  70.000000  0.004405    227    1.0
    edu     ratio    len    sum
0   0.0  0.006607  62512  413.0
1  10.0  0.000000      4    0.0
2  20.0  0.000000     38    0.0
3  30.0  0.000000     68    0.0
4  40.0  0.000000    111    0.0
5  47.0  0.000000      1    0.0
6  60.0  0.000000      1    0.0
7  70.0  0.000000     34    0.0
       x_34     ratio    len    sum
0  1.000000  0.009826   7531   74.0
1  2.000000  0.010051   4875   49.0
2  3.000000  0.008626   6608   57.0
3  3.624522  0.025000    160    4.0
4  4.000000  0.008659  14783  128.0
5  5.000000  0.007966   6402   51.0
6  6.000000  0.009633   7474   72.0
       x_34     ratio    len    sum
0  1.000000  0.006873  10039   69.0
1  2.000000  0.007155   5730   41.0
2  3.000000  0.006533  11174   73.0
3  3.624522  0.046296    108    5.0
4  4.000000  0.007512  16906  127.0
5  5.000000  0.004910   8961   44.0
6  6.000000  0.005482   9851   54.0
       x_33     ratio    len    sum
0  1.000000  0.008458  15607  132.0
1  2.000000  0.008826   9404   83.0
2  2.484723  0.025000    160    4.0
3  3.000000  0.009317  14705  137.0
4  4.000000  0.008662   3579   31.0
5  5.000000  0.011974   3758   45.0
6  6.000000  0.004839    620    3.0
       x_33     ratio    len    sum
0  1.000000  0.005231  19118  100.0
1  2.000000  0.004363   9856   43.0
2  2.484723  0.046296    108    5.0
3  3.000000  0.007178  21593  155.0
4  4.000000  0.007337   5997   44.0
5  5.000000  0.011955   5437   65.0
6  6.000000  0.001515    660    1.0
    setupHour     ratio   len   sum
0         0.0  0.002195  1367   3.0
1         1.0  0.006167  1135   7.0
2         2.0  0.007078   989   7.0
3         3.0  0.007634   786   6.0
4         4.0  0.011968   752   9.0
5         5.0  0.016929   827  14.0
6         6.0  0.014286   840  12.0
7         7.0  0.009557  1151  11.0
8         8.0  0.010811  1480  16.0
9         9.0  0.009366  2349  22.0
10       10.0  0.006111  2782  17.0
11       11.0  0.009928  2921  29.0
12       12.0  0.013709  2553  35.0
13       13.0  0.010231  2639  27.0
14       14.0  0.009336  2785  26.0
15       15.0  0.012323  3246  40.0
16       16.0  0.011033  3263  36.0
17       17.0  0.010727  3356  36.0
18       18.0  0.006163  2596  16.0
19       19.0  0.005415  2216  12.0
20       20.0  0.009740  2156  21.0
21       21.0  0.003772  2121   8.0
22       22.0  0.005336  1874  10.0
23       23.0  0.009096  1649  15.0
    setupHour     ratio   len   sum
0         0.0  0.007083  1553  11.0
1         1.0  0.006776  1033   7.0
2         2.0  0.008996   667   6.0
3         3.0  0.010178   393   4.0
4         4.0  0.007353   272   2.0
5         5.0  0.003012   332   1.0
6         6.0  0.010369   868   9.0
7         7.0  0.005856  1537   9.0
8         8.0  0.004466  2239  10.0
9         9.0  0.004900  3265  16.0
10       10.0  0.008066  4091  33.0
11       11.0  0.004444  4500  20.0
12       12.0  0.005916  3888  23.0
13       13.0  0.007744  3745  29.0
14       14.0  0.007123  3931  28.0
15       15.0  0.007817  3838  30.0
16       16.0  0.007153  4334  31.0
17       17.0  0.004735  4646  22.0
18       18.0  0.005977  3848  23.0
19       19.0  0.008772  3306  29.0
20       20.0  0.007545  3181  24.0
21       21.0  0.003074  2928   9.0
22       22.0  0.007800  2436  19.0
23       23.0  0.009288  1938  18.0
         lmt     ratio  len  sum
0      0.167  0.016393  122  2.0
1      0.222  0.017544   57  1.0
2      0.335  0.000000    1  0.0
3      0.356  0.000000    1  0.0
4      0.363  0.031250   96  3.0
5      0.368  0.000000    2  0.0
6      0.396  0.025316   79  2.0
7      0.402  0.500000    2  1.0
8      0.404  0.000000    1  0.0
9      0.430  0.020270  148  3.0
10     0.433  0.000000    7  0.0
11     0.435  0.000000    3  0.0
12     0.463  0.019231  156  3.0
13     0.467  0.000000    3  0.0
14     0.468  0.000000    1  0.0
15     0.471  0.000000    1  0.0
16     0.496  0.026316  114  3.0
17     0.500  0.000000   16  0.0
18     0.502  0.166667    6  1.0
19     0.503  0.000000    1  0.0
20     0.504  0.000000    1  0.0
21     0.530  0.019802  202  4.0
22     0.533  0.000000    9  0.0
23     0.535  0.000000    1  0.0
24     0.550  0.000000    1  0.0
25     0.563  0.000000   63  0.0
26     0.567  0.000000   25  0.0
27     0.568  0.000000    2  0.0
28     0.570  0.000000    2  0.0
29     0.571  0.000000    1  0.0
...      ...       ...  ...  ...
1414  56.296  0.000000   19  0.0
1415  59.630  0.000000   17  0.0
1416  60.630  0.000000    1  0.0
1417  60.935  0.000000    1  0.0
1418  62.137  0.000000    1  0.0
1419  62.630  0.000000    1  0.0
1420  62.963  0.000000   13  0.0
1421  63.533  0.000000    1  0.0
1422  65.300  0.000000    1  0.0
1423  66.000  0.000000    1  0.0
1424  66.296  0.000000   19  0.0
1425  66.667  0.000000    5  0.0
1426  67.100  0.000000    1  0.0
1427  69.630  0.000000    8  0.0
1428  72.963  0.000000    3  0.0
1429  74.300  0.000000    1  0.0
1430  76.296  0.000000    2  0.0
1431  76.367  0.000000    1  0.0
1432  76.400  0.000000    1  0.0
1433  79.630  0.000000    4  0.0
1434  80.835  0.000000    1  0.0
1435  82.963  0.000000    7  0.0
1436  83.333  0.000000    1  0.0
1437  86.296  0.000000    2  0.0
1438  88.003  0.000000    1  0.0
1439  89.630  0.000000    4  0.0
1440  92.837  0.000000    1  0.0
1441  92.963  0.000000    9  0.0
1442  96.296  0.000000    1  0.0
1443  99.630  0.000000    4  0.0

[1444 rows x 4 columns]
         lmt     ratio  len   sum
0      0.363  0.000000    4   0.0
1      0.430  0.047619   21   1.0
2      0.433  0.050000   20   1.0
3      0.463  0.000000   23   0.0
4      0.467  0.000000    2   0.0
5      0.496  0.032258   31   1.0
6      0.500  0.020000   50   1.0
7      0.530  0.000000   49   0.0
8      0.533  0.000000   31   0.0
9      0.563  0.000000    6   0.0
10     0.567  0.000000   40   0.0
11     0.596  0.000000   83   0.0
12     0.600  0.000000   37   0.0
13     0.630  0.000000   20   0.0
14     0.633  0.000000   33   0.0
15     0.663  0.000000   68   0.0
16     0.667  0.013889  360   5.0
17     0.696  0.026316   76   2.0
18     0.700  0.012658   79   1.0
19     0.730  0.000000   21   0.0
20     0.733  0.020913  526  11.0
21     0.763  0.031746   63   2.0
22     0.767  0.018868   53   1.0
23     0.796  0.042254   71   3.0
24     0.800  0.020979  143   3.0
25     0.830  0.018018  111   2.0
26     0.833  0.000000   51   0.0
27     0.863  0.025000   40   1.0
28     0.867  0.007663  261   2.0
29     0.896  0.000000   81   0.0
...      ...       ...  ...   ...
1057  52.533  0.000000    1   0.0
1058  52.700  0.000000    1   0.0
1059  52.933  0.000000    1   0.0
1060  52.963  0.000000   20   0.0
1061  53.800  0.000000    1   0.0
1062  55.033  0.000000    1   0.0
1063  55.133  0.000000    1   0.0
1064  55.400  0.000000    1   0.0
1065  55.433  0.000000    1   0.0
1066  55.867  0.000000    1   0.0
1067  56.296  0.000000   16   0.0
1068  56.300  0.000000    1   0.0
1069  59.630  0.000000   16   0.0
1070  59.867  0.000000    1   0.0
1071  60.600  0.000000    1   0.0
1072  62.963  0.000000   18   0.0
1073  63.167  0.000000    1   0.0
1074  64.133  0.000000    1   0.0
1075  66.296  0.000000   11   0.0
1076  66.667  0.000000   20   0.0
1077  69.630  0.000000   24   0.0
1078  72.963  0.000000   12   0.0
1079  76.296  0.000000    7   0.0
1080  79.630  0.000000    5   0.0
1081  82.963  0.000000    6   0.0
1082  86.296  0.000000    7   0.0
1083  89.630  0.000000    5   0.0
1084  92.963  0.000000    3   0.0
1085  96.296  0.000000    1   0.0
1086  99.630  0.000000    6   0.0

[1087 rows x 4 columns]
#lgb训练模型
def lgb_train(pout_train, test_df,target):
    folds = StratifiedKFold(n_splits=10, shuffle=False, random_state=666)
    oof = np.zeros(len(pout_train))
    feature_importance_df = pd.DataFrame()
    predictions = np.zeros(len(test_df))

    param = {'num_leaves': 10,
             'min_data_in_leaf': 21,
             'objective': 'binary',
             'max_depth': 5,
             'learning_rate': 0.1,
             "boosting": "gbdt",
             "feature_fraction": 1,
             "bagging_freq": 1,
             "bagging_fraction":1,
             "bagging_seed": 11,
             "metric": 'auc',
             "lambda_l1": 0,
             "verbosity": -1,
             "nthread": 4,
             "random_state": 666}

    for fold_, (trn_idx, val_idx) in enumerate(folds.split(pout_train.values, target)):
        print("Fold {}".format(fold_))
        trn_data = lgb.Dataset(pout_train.values[trn_idx], label=target.values[trn_idx])
        val_data = lgb.Dataset(pout_train.values[val_idx], label=target.values[val_idx])

        num_round = 100000
        clf = lgb.train(param, trn_data, num_round, valid_sets=[trn_data, val_data], verbose_eval=100,
                        early_stopping_rounds=300)
        oof[val_idx] = clf.predict(pout_train.values[val_idx], num_iteration=clf.best_iteration)
        #predictions += clf.predict(test_df.values, num_iteration=clf.best_iteration) / folds.n_splits
        fold_importance_df = pd.DataFrame()
        fold_importance_df["Feature"] = pout_train.columns
        fold_importance_df["importance"] = clf.feature_importance()
        fold_importance_df["fold"] = fold_ + 1
        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)
    print("CV score: {:<8.5f}".format(roc_auc_score(target, oof)))

    sub = pd.DataFrame()
    sub['id'] = test_pdData.index
    sub['target'] = predictions
    sub.to_csv('/home/kesci/work/result_DC_lgb.csv', index=False)

    cols = (feature_importance_df[["Feature", "importance"]]
            .groupby("Feature")
            .mean()
            .sort_values(by="importance", ascending=False)[:150].index)
    best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]

    plt.figure(figsize=(14, 30))
    sns.barplot(x="importance", y="Feature", data=best_features.sort_values(by="importance", ascending=False))
    plt.title('Features importance (averaged/folds)')
    plt.tight_layout()
    plt.show()
#xgb模型
def xgb_train(pout_train,test_df,target):
    folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=666)
    #folds = KFold(n_splits=5, shuffle=True, random_state=1234)
    oof = np.zeros(len(pout_train))
    feature_importance_df = pd.DataFrame()
    predictions = np.zeros(len(test_df))
    #predictions2 = np.zeros(len(df))
    
    sum_num = 0
    for fold_, (trn_idx, val_idx) in enumerate(folds.split(pout_train.values, target)):
        print("Fold {}".format(fold_))

        #trn_data,trn_label= pout_train.values[trn_idx], target[trn_idx]
        #val_data,val_label= pout_train.values[val_idx], target[val_idx]
        trn_data, trn_label = pout_train.iloc[trn_idx], target[trn_idx]
        val_data,val_label= pout_train.iloc[val_idx], target[val_idx]

        trn_data,val_data=trn_data.values,val_data.values
        trn_label,val_label=trn_label.values,val_label.values
        clf = XGBClassifier(max_depth=4,gamma=0,n_estimators=200,eta=0.03,min_child_weight=1)

        view_list=[(trn_data,trn_label),(val_data,val_label)]
        clf.fit(trn_data,trn_label,eval_set=view_list,eval_metric='auc',early_stopping_rounds=200)
        y_val, y_val_pred = val_label, clf.predict_proba(val_data)[:,1]
        auc_score=roc_auc_score(y_val, y_val_pred)
        print(auc_score)
        print('-------------------------------------------------------------------------------------------------')
        oof[val_idx] = clf.predict_proba(pout_train.values[val_idx])[:,1]

        sum_num += 1
        predictions += clf.predict_proba(test_df.values)[:,1]
        #predictions2 += clf.predict_proba(df.values)[:,1]

        fold_importance_df = pd.DataFrame()
        fold_importance_df["Feature"] = pout_train.columns
        fold_importance_df["importance"] = clf.feature_importances_
        fold_importance_df["fold"] = fold_ + 1
        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)
    predictions = predictions / sum_num
    #predictions2 = predictions2 / sum_num
    print("CV score: {:<8.5f}".format(roc_auc_score(target, oof)))

    sub = pd.DataFrame()
    sub['id'] = test_pdData.index
    sub['target'] = predictions
    sub.to_csv('/home/kesci/work/sub_result_DC_', index=False)

    cols = (feature_importance_df[["Feature", "importance"]]
            .groupby("Feature")
            .mean()
            .sort_values(by="importance", ascending=False)[:150].index)
    best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]

    plt.figure(figsize=(14, 30))
    sns.barplot(x="importance", y="Feature", data=best_features.sort_values(by="importance", ascending=False))
    plt.title('Features importance (averaged/folds)')
    plt.tight_layout()
    plt.show()
    
target=train_pdData['y']
train_df=train_pdData.drop(['y'],axis=1)
test_df=test_pdData.copy()
#进行特征的one_hot处理
all_df0=pd.concat([train_df,test_df],axis=0)
one_enc=preprocessing.OneHotEncoder(sparse=False).fit(all_df0[categorical_feature_list].values)
one_hot_train=one_enc.transform(train_df[categorical_feature_list].values)
one_hot_test=one_enc.transform(test_df[categorical_feature_list].values)
column_num=np.shape(one_hot_test)[1]
name_list=['one_hot'+str(i) for i in range(column_num)]
for i in range(column_num):
    train_df[name_list[i]]=one_hot_train[:,i]
    test_df[name_list[i]] = one_hot_test[:, i]
#去除重复的特征
train_df=train_df.T.drop_duplicates(keep='first').T
test_df=test_df.drop([i for i in test_df.columns if i not in train_df.columns],axis=1)
print(len(train_df.columns))
print(train_df.columns)
print(test_df.columns)
134
Index(['certId', 'loanProduct', 'gender', 'age', 'dist', 'edu', 'job', 'lmt',
       'basicLevel', 'x_0',
       ...
       'one_hot48', 'one_hot49', 'one_hot50', 'one_hot51', 'one_hot52',
       'one_hot53', 'one_hot54', 'one_hot55', 'one_hot56', 'one_hot57'],
      dtype='object', length=134)
Index(['certId', 'loanProduct', 'gender', 'age', 'dist', 'edu', 'job', 'lmt',
       'basicLevel', 'x_0',
       ...
       'one_hot48', 'one_hot49', 'one_hot50', 'one_hot51', 'one_hot52',
       'one_hot53', 'one_hot54', 'one_hot55', 'one_hot56', 'one_hot57'],
      dtype='object', length=134)
train_df0=train_df.drop(['isNew'],axis=1)
test_df0=test_df.drop(['isNew'],axis=1)
train_df0['magic']=train_df0['x_45'].values+train_df0['x_46'].values
test_df0['magic']=test_df0['x_45'].values+test_df0['x_46'].values
print(train_df0.shape[0])
print(train_df0.columns)
xgb_train(train_df0,test_df0,target)
110602
Index(['certId', 'loanProduct', 'gender', 'age', 'dist', 'edu', 'job', 'lmt',
       'basicLevel', 'x_0',
       ...
       'one_hot49', 'one_hot50', 'one_hot51', 'one_hot52', 'one_hot53',
       'one_hot54', 'one_hot55', 'one_hot56', 'one_hot57', 'magic'],
      dtype='object', length=134)
Fold 0
[0]	validation_0-auc:0.580234	validation_1-auc:0.542289
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.580234	validation_1-auc:0.542289
[2]	validation_0-auc:0.580234	validation_1-auc:0.542289
[3]	validation_0-auc:0.641842	validation_1-auc:0.626904
[4]	validation_0-auc:0.641842	validation_1-auc:0.626904
[5]	validation_0-auc:0.64524	validation_1-auc:0.628987
[6]	validation_0-auc:0.652368	validation_1-auc:0.632012
[7]	validation_0-auc:0.65408	validation_1-auc:0.628741
[8]	validation_0-auc:0.655651	validation_1-auc:0.628593
[9]	validation_0-auc:0.660451	validation_1-auc:0.631968
[10]	validation_0-auc:0.662049	validation_1-auc:0.632065
[11]	validation_0-auc:0.662906	validation_1-auc:0.632558
[12]	validation_0-auc:0.664687	validation_1-auc:0.634214
[13]	validation_0-auc:0.664683	validation_1-auc:0.633291
[14]	validation_0-auc:0.666388	validation_1-auc:0.632456
[15]	validation_0-auc:0.666123	validation_1-auc:0.632046
[16]	validation_0-auc:0.667974	validation_1-auc:0.634128
[17]	validation_0-auc:0.667926	validation_1-auc:0.634337
[18]	validation_0-auc:0.670685	validation_1-auc:0.634546
[19]	validation_0-auc:0.671557	validation_1-auc:0.634292
[20]	validation_0-auc:0.672688	validation_1-auc:0.634788
[21]	validation_0-auc:0.692541	validation_1-auc:0.641643
[22]	validation_0-auc:0.693438	validation_1-auc:0.641457
[23]	validation_0-auc:0.694839	validation_1-auc:0.641944
[24]	validation_0-auc:0.705269	validation_1-auc:0.651541
[25]	validation_0-auc:0.704531	validation_1-auc:0.647899
[26]	validation_0-auc:0.70656	validation_1-auc:0.648427
[27]	validation_0-auc:0.709892	validation_1-auc:0.652896
[28]	validation_0-auc:0.71115	validation_1-auc:0.652302
[29]	validation_0-auc:0.713164	validation_1-auc:0.651641
[30]	validation_0-auc:0.713775	validation_1-auc:0.651863
[31]	validation_0-auc:0.714811	validation_1-auc:0.651742
[32]	validation_0-auc:0.715661	validation_1-auc:0.652341
[33]	validation_0-auc:0.7166	validation_1-auc:0.653703
[34]	validation_0-auc:0.718357	validation_1-auc:0.656519
[35]	validation_0-auc:0.720555	validation_1-auc:0.655542
[36]	validation_0-auc:0.729529	validation_1-auc:0.656932
[37]	validation_0-auc:0.733756	validation_1-auc:0.654227
[38]	validation_0-auc:0.736561	validation_1-auc:0.65723
[39]	validation_0-auc:0.740218	validation_1-auc:0.655716
[40]	validation_0-auc:0.74288	validation_1-auc:0.659792
[41]	validation_0-auc:0.744538	validation_1-auc:0.663838
[42]	validation_0-auc:0.747493	validation_1-auc:0.66276
[43]	validation_0-auc:0.750494	validation_1-auc:0.663051
[44]	validation_0-auc:0.753934	validation_1-auc:0.662794
[45]	validation_0-auc:0.756203	validation_1-auc:0.662941
[46]	validation_0-auc:0.75733	validation_1-auc:0.665878
[47]	validation_0-auc:0.760414	validation_1-auc:0.671127
[48]	validation_0-auc:0.764472	validation_1-auc:0.672677
[49]	validation_0-auc:0.766993	validation_1-auc:0.675133
[50]	validation_0-auc:0.770123	validation_1-auc:0.675004
[51]	validation_0-auc:0.772994	validation_1-auc:0.679638
[52]	validation_0-auc:0.774351	validation_1-auc:0.678878
[53]	validation_0-auc:0.777148	validation_1-auc:0.678502
[54]	validation_0-auc:0.779694	validation_1-auc:0.67897
[55]	validation_0-auc:0.784217	validation_1-auc:0.684592
[56]	validation_0-auc:0.785788	validation_1-auc:0.68507
[57]	validation_0-auc:0.787566	validation_1-auc:0.685738
[58]	validation_0-auc:0.789535	validation_1-auc:0.687605
[59]	validation_0-auc:0.790372	validation_1-auc:0.688676
[60]	validation_0-auc:0.7934	validation_1-auc:0.68842
[61]	validation_0-auc:0.7953	validation_1-auc:0.687844
[62]	validation_0-auc:0.796628	validation_1-auc:0.689562
[63]	validation_0-auc:0.798585	validation_1-auc:0.688885
[64]	validation_0-auc:0.799643	validation_1-auc:0.688722
[65]	validation_0-auc:0.801652	validation_1-auc:0.688486
[66]	validation_0-auc:0.802681	validation_1-auc:0.689102
[67]	validation_0-auc:0.804258	validation_1-auc:0.686471
[68]	validation_0-auc:0.806534	validation_1-auc:0.686701
[69]	validation_0-auc:0.808087	validation_1-auc:0.68638
[70]	validation_0-auc:0.809843	validation_1-auc:0.685467
[71]	validation_0-auc:0.810485	validation_1-auc:0.684764
[72]	validation_0-auc:0.814536	validation_1-auc:0.683515
[73]	validation_0-auc:0.817554	validation_1-auc:0.684675
[74]	validation_0-auc:0.819244	validation_1-auc:0.687883
[75]	validation_0-auc:0.820395	validation_1-auc:0.687451
[76]	validation_0-auc:0.821043	validation_1-auc:0.689633
[77]	validation_0-auc:0.82321	validation_1-auc:0.691524
[78]	validation_0-auc:0.823699	validation_1-auc:0.691918
[79]	validation_0-auc:0.825127	validation_1-auc:0.693122
[80]	validation_0-auc:0.82632	validation_1-auc:0.695181
[81]	validation_0-auc:0.826935	validation_1-auc:0.696486
[82]	validation_0-auc:0.83015	validation_1-auc:0.697182
[83]	validation_0-auc:0.832772	validation_1-auc:0.696161
[84]	validation_0-auc:0.833749	validation_1-auc:0.69668
[85]	validation_0-auc:0.835731	validation_1-auc:0.696348
[86]	validation_0-auc:0.837724	validation_1-auc:0.697532
[87]	validation_0-auc:0.839088	validation_1-auc:0.696703
[88]	validation_0-auc:0.839941	validation_1-auc:0.697302
[89]	validation_0-auc:0.842334	validation_1-auc:0.696911
[90]	validation_0-auc:0.843707	validation_1-auc:0.696889
[91]	validation_0-auc:0.844339	validation_1-auc:0.696492
[92]	validation_0-auc:0.844884	validation_1-auc:0.696821
[93]	validation_0-auc:0.845969	validation_1-auc:0.695865
[94]	validation_0-auc:0.847433	validation_1-auc:0.695396
[95]	validation_0-auc:0.848984	validation_1-auc:0.696726
[96]	validation_0-auc:0.849871	validation_1-auc:0.696066
[97]	validation_0-auc:0.852079	validation_1-auc:0.697102
[98]	validation_0-auc:0.85239	validation_1-auc:0.697797
[99]	validation_0-auc:0.854514	validation_1-auc:0.69716
[100]	validation_0-auc:0.854766	validation_1-auc:0.696777
[101]	validation_0-auc:0.85532	validation_1-auc:0.697441
[102]	validation_0-auc:0.856394	validation_1-auc:0.697599
[103]	validation_0-auc:0.859145	validation_1-auc:0.696791
[104]	validation_0-auc:0.859806	validation_1-auc:0.698763
[105]	validation_0-auc:0.861474	validation_1-auc:0.699243
[106]	validation_0-auc:0.861697	validation_1-auc:0.699508
[107]	validation_0-auc:0.861977	validation_1-auc:0.698921
[108]	validation_0-auc:0.862253	validation_1-auc:0.699614
[109]	validation_0-auc:0.863617	validation_1-auc:0.699434
[110]	validation_0-auc:0.864655	validation_1-auc:0.698615
[111]	validation_0-auc:0.865029	validation_1-auc:0.699983
[112]	validation_0-auc:0.865932	validation_1-auc:0.7008
[113]	validation_0-auc:0.866851	validation_1-auc:0.700865
[114]	validation_0-auc:0.868072	validation_1-auc:0.700658
[115]	validation_0-auc:0.868752	validation_1-auc:0.701353
[116]	validation_0-auc:0.869869	validation_1-auc:0.701315
[117]	validation_0-auc:0.871274	validation_1-auc:0.702019
[118]	validation_0-auc:0.872778	validation_1-auc:0.701763
[119]	validation_0-auc:0.874815	validation_1-auc:0.702295
[120]	validation_0-auc:0.874951	validation_1-auc:0.702482
[121]	validation_0-auc:0.876006	validation_1-auc:0.701845
[122]	validation_0-auc:0.876264	validation_1-auc:0.702187
[123]	validation_0-auc:0.878007	validation_1-auc:0.701742
[124]	validation_0-auc:0.878561	validation_1-auc:0.702653
[125]	validation_0-auc:0.878814	validation_1-auc:0.703164
[126]	validation_0-auc:0.879507	validation_1-auc:0.702892
[127]	validation_0-auc:0.880304	validation_1-auc:0.702598
[128]	validation_0-auc:0.882628	validation_1-auc:0.70215
[129]	validation_0-auc:0.884128	validation_1-auc:0.701751
[130]	validation_0-auc:0.885563	validation_1-auc:0.700584
[131]	validation_0-auc:0.885715	validation_1-auc:0.700927
[132]	validation_0-auc:0.886538	validation_1-auc:0.70272
[133]	validation_0-auc:0.886789	validation_1-auc:0.703263
[134]	validation_0-auc:0.887741	validation_1-auc:0.702395
[135]	validation_0-auc:0.888132	validation_1-auc:0.701631
[136]	validation_0-auc:0.890462	validation_1-auc:0.701948
[137]	validation_0-auc:0.89164	validation_1-auc:0.702426
[138]	validation_0-auc:0.892487	validation_1-auc:0.701063
[139]	validation_0-auc:0.892876	validation_1-auc:0.700823
[140]	validation_0-auc:0.893983	validation_1-auc:0.701127
[141]	validation_0-auc:0.895077	validation_1-auc:0.701062
[142]	validation_0-auc:0.895823	validation_1-auc:0.701071
[143]	validation_0-auc:0.896259	validation_1-auc:0.702376
[144]	validation_0-auc:0.896457	validation_1-auc:0.702222
[145]	validation_0-auc:0.898207	validation_1-auc:0.702345
[146]	validation_0-auc:0.898514	validation_1-auc:0.701702
[147]	validation_0-auc:0.899641	validation_1-auc:0.702289
[148]	validation_0-auc:0.899988	validation_1-auc:0.702039
[149]	validation_0-auc:0.901214	validation_1-auc:0.700496
[150]	validation_0-auc:0.902245	validation_1-auc:0.701378
[151]	validation_0-auc:0.902726	validation_1-auc:0.700966
[152]	validation_0-auc:0.902878	validation_1-auc:0.700541
[153]	validation_0-auc:0.90359	validation_1-auc:0.700682
[154]	validation_0-auc:0.904974	validation_1-auc:0.698819
[155]	validation_0-auc:0.905056	validation_1-auc:0.699682
[156]	validation_0-auc:0.905996	validation_1-auc:0.699313
[157]	validation_0-auc:0.906202	validation_1-auc:0.699913
[158]	validation_0-auc:0.90695	validation_1-auc:0.700942
[159]	validation_0-auc:0.907071	validation_1-auc:0.700898
[160]	validation_0-auc:0.907494	validation_1-auc:0.700691
[161]	validation_0-auc:0.907948	validation_1-auc:0.699457
[162]	validation_0-auc:0.909127	validation_1-auc:0.698071
[163]	validation_0-auc:0.909793	validation_1-auc:0.69829
[164]	validation_0-auc:0.909865	validation_1-auc:0.698499
[165]	validation_0-auc:0.911019	validation_1-auc:0.696291
[166]	validation_0-auc:0.910878	validation_1-auc:0.696379
[167]	validation_0-auc:0.911505	validation_1-auc:0.696459
[168]	validation_0-auc:0.912618	validation_1-auc:0.695041
[169]	validation_0-auc:0.912753	validation_1-auc:0.695207
[170]	validation_0-auc:0.913063	validation_1-auc:0.695148
[171]	validation_0-auc:0.913423	validation_1-auc:0.69495
[172]	validation_0-auc:0.913871	validation_1-auc:0.695184
[173]	validation_0-auc:0.914005	validation_1-auc:0.695161
[174]	validation_0-auc:0.91504	validation_1-auc:0.694216
[175]	validation_0-auc:0.915514	validation_1-auc:0.694441
[176]	validation_0-auc:0.916879	validation_1-auc:0.695497
[177]	validation_0-auc:0.917107	validation_1-auc:0.694718
[178]	validation_0-auc:0.917353	validation_1-auc:0.694078
[179]	validation_0-auc:0.917361	validation_1-auc:0.694621
[180]	validation_0-auc:0.917417	validation_1-auc:0.694841
[181]	validation_0-auc:0.917521	validation_1-auc:0.694773
[182]	validation_0-auc:0.918286	validation_1-auc:0.694206
[183]	validation_0-auc:0.918795	validation_1-auc:0.69435
[184]	validation_0-auc:0.919087	validation_1-auc:0.694802
[185]	validation_0-auc:0.919634	validation_1-auc:0.694454
[186]	validation_0-auc:0.920619	validation_1-auc:0.695553
[187]	validation_0-auc:0.921311	validation_1-auc:0.695938
[188]	validation_0-auc:0.922188	validation_1-auc:0.694641
[189]	validation_0-auc:0.922685	validation_1-auc:0.694784
[190]	validation_0-auc:0.92316	validation_1-auc:0.694657
[191]	validation_0-auc:0.923457	validation_1-auc:0.694934
[192]	validation_0-auc:0.923859	validation_1-auc:0.694552
[193]	validation_0-auc:0.923907	validation_1-auc:0.694701
[194]	validation_0-auc:0.924477	validation_1-auc:0.695037
[195]	validation_0-auc:0.924565	validation_1-auc:0.695402
[196]	validation_0-auc:0.924669	validation_1-auc:0.695023
[197]	validation_0-auc:0.924778	validation_1-auc:0.695405
[198]	validation_0-auc:0.925182	validation_1-auc:0.694455
[199]	validation_0-auc:0.925468	validation_1-auc:0.69453
0.7032627336648946
-------------------------------------------------------------------------------------------------
Fold 1
[0]	validation_0-auc:0.579599	validation_1-auc:0.547989
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.579599	validation_1-auc:0.547989
[2]	validation_0-auc:0.645316	validation_1-auc:0.603206
[3]	validation_0-auc:0.646186	validation_1-auc:0.603206
[4]	validation_0-auc:0.646186	validation_1-auc:0.603206
[5]	validation_0-auc:0.648709	validation_1-auc:0.605215
[6]	validation_0-auc:0.648709	validation_1-auc:0.605215
[7]	validation_0-auc:0.655859	validation_1-auc:0.612652
[8]	validation_0-auc:0.661276	validation_1-auc:0.613346
[9]	validation_0-auc:0.665708	validation_1-auc:0.617333
[10]	validation_0-auc:0.667967	validation_1-auc:0.618175
[11]	validation_0-auc:0.66966	validation_1-auc:0.618259
[12]	validation_0-auc:0.670355	validation_1-auc:0.61915
[13]	validation_0-auc:0.670772	validation_1-auc:0.618973
[14]	validation_0-auc:0.673047	validation_1-auc:0.618228
[15]	validation_0-auc:0.674594	validation_1-auc:0.619318
[16]	validation_0-auc:0.675171	validation_1-auc:0.618366
[17]	validation_0-auc:0.675485	validation_1-auc:0.61911
[18]	validation_0-auc:0.676331	validation_1-auc:0.619388
[19]	validation_0-auc:0.677198	validation_1-auc:0.620101
[20]	validation_0-auc:0.677781	validation_1-auc:0.621607
[21]	validation_0-auc:0.678888	validation_1-auc:0.621581
[22]	validation_0-auc:0.6795	validation_1-auc:0.622186
[23]	validation_0-auc:0.679755	validation_1-auc:0.622229
[24]	validation_0-auc:0.69364	validation_1-auc:0.645454
[25]	validation_0-auc:0.694222	validation_1-auc:0.645921
[26]	validation_0-auc:0.696088	validation_1-auc:0.646852
[27]	validation_0-auc:0.698153	validation_1-auc:0.648372
[28]	validation_0-auc:0.706556	validation_1-auc:0.665824
[29]	validation_0-auc:0.71398	validation_1-auc:0.657572
[30]	validation_0-auc:0.717469	validation_1-auc:0.665083
[31]	validation_0-auc:0.719576	validation_1-auc:0.667375
[32]	validation_0-auc:0.720418	validation_1-auc:0.667038
[33]	validation_0-auc:0.722394	validation_1-auc:0.669108
[34]	validation_0-auc:0.724898	validation_1-auc:0.673807
[35]	validation_0-auc:0.72555	validation_1-auc:0.672476
[36]	validation_0-auc:0.72755	validation_1-auc:0.674989
[37]	validation_0-auc:0.730258	validation_1-auc:0.674297
[38]	validation_0-auc:0.734463	validation_1-auc:0.673438
[39]	validation_0-auc:0.735861	validation_1-auc:0.675498
[40]	validation_0-auc:0.738957	validation_1-auc:0.676065
[41]	validation_0-auc:0.739914	validation_1-auc:0.677706
[42]	validation_0-auc:0.745517	validation_1-auc:0.674186
[43]	validation_0-auc:0.752375	validation_1-auc:0.673977
[44]	validation_0-auc:0.754492	validation_1-auc:0.670945
[45]	validation_0-auc:0.756823	validation_1-auc:0.672267
[46]	validation_0-auc:0.75825	validation_1-auc:0.674945
[47]	validation_0-auc:0.761115	validation_1-auc:0.675043
[48]	validation_0-auc:0.763159	validation_1-auc:0.673484
[49]	validation_0-auc:0.768428	validation_1-auc:0.679119
[50]	validation_0-auc:0.769526	validation_1-auc:0.680535
[51]	validation_0-auc:0.773055	validation_1-auc:0.689326
[52]	validation_0-auc:0.774507	validation_1-auc:0.688881
[53]	validation_0-auc:0.776785	validation_1-auc:0.691521
[54]	validation_0-auc:0.778304	validation_1-auc:0.693153
[55]	validation_0-auc:0.780782	validation_1-auc:0.693945
[56]	validation_0-auc:0.78188	validation_1-auc:0.694133
[57]	validation_0-auc:0.784725	validation_1-auc:0.699872
[58]	validation_0-auc:0.78672	validation_1-auc:0.698625
[59]	validation_0-auc:0.790352	validation_1-auc:0.704238
[60]	validation_0-auc:0.791038	validation_1-auc:0.705379
[61]	validation_0-auc:0.792925	validation_1-auc:0.708636
[62]	validation_0-auc:0.796437	validation_1-auc:0.710293
[63]	validation_0-auc:0.797572	validation_1-auc:0.712047
[64]	validation_0-auc:0.797882	validation_1-auc:0.712948
[65]	validation_0-auc:0.800606	validation_1-auc:0.716123
[66]	validation_0-auc:0.801033	validation_1-auc:0.716115
[67]	validation_0-auc:0.8035	validation_1-auc:0.712576
[68]	validation_0-auc:0.805213	validation_1-auc:0.7132
[69]	validation_0-auc:0.806934	validation_1-auc:0.713807
[70]	validation_0-auc:0.808012	validation_1-auc:0.713731
[71]	validation_0-auc:0.809355	validation_1-auc:0.715873
[72]	validation_0-auc:0.811836	validation_1-auc:0.716954
[73]	validation_0-auc:0.813377	validation_1-auc:0.717414
[74]	validation_0-auc:0.814368	validation_1-auc:0.719303
[75]	validation_0-auc:0.815795	validation_1-auc:0.719535
[76]	validation_0-auc:0.817958	validation_1-auc:0.718383
[77]	validation_0-auc:0.819422	validation_1-auc:0.718092
[78]	validation_0-auc:0.819275	validation_1-auc:0.718407
[79]	validation_0-auc:0.822029	validation_1-auc:0.720569
[80]	validation_0-auc:0.824489	validation_1-auc:0.722845
[81]	validation_0-auc:0.826138	validation_1-auc:0.724744
[82]	validation_0-auc:0.828184	validation_1-auc:0.725489
[83]	validation_0-auc:0.828885	validation_1-auc:0.726
[84]	validation_0-auc:0.829608	validation_1-auc:0.72607
[85]	validation_0-auc:0.831358	validation_1-auc:0.726591
[86]	validation_0-auc:0.832257	validation_1-auc:0.72602
[87]	validation_0-auc:0.833333	validation_1-auc:0.727323
[88]	validation_0-auc:0.834061	validation_1-auc:0.726565
[89]	validation_0-auc:0.835584	validation_1-auc:0.724782
[90]	validation_0-auc:0.835875	validation_1-auc:0.725846
[91]	validation_0-auc:0.836526	validation_1-auc:0.724619
[92]	validation_0-auc:0.838184	validation_1-auc:0.72476
[93]	validation_0-auc:0.83956	validation_1-auc:0.724097
[94]	validation_0-auc:0.840933	validation_1-auc:0.723895
[95]	validation_0-auc:0.842217	validation_1-auc:0.725831
[96]	validation_0-auc:0.842571	validation_1-auc:0.725812
[97]	validation_0-auc:0.842925	validation_1-auc:0.726046
[98]	validation_0-auc:0.843316	validation_1-auc:0.726358
[99]	validation_0-auc:0.845341	validation_1-auc:0.727162
[100]	validation_0-auc:0.845837	validation_1-auc:0.727774
[101]	validation_0-auc:0.847133	validation_1-auc:0.727089
[102]	validation_0-auc:0.848431	validation_1-auc:0.726822
[103]	validation_0-auc:0.849903	validation_1-auc:0.726598
[104]	validation_0-auc:0.850173	validation_1-auc:0.725889
[105]	validation_0-auc:0.851219	validation_1-auc:0.726542
[106]	validation_0-auc:0.851614	validation_1-auc:0.726199
[107]	validation_0-auc:0.852741	validation_1-auc:0.726402
[108]	validation_0-auc:0.853431	validation_1-auc:0.726264
[109]	validation_0-auc:0.854672	validation_1-auc:0.727312
[110]	validation_0-auc:0.855736	validation_1-auc:0.726282
[111]	validation_0-auc:0.856055	validation_1-auc:0.724058
[112]	validation_0-auc:0.857646	validation_1-auc:0.722929
[113]	validation_0-auc:0.858194	validation_1-auc:0.723512
[114]	validation_0-auc:0.858467	validation_1-auc:0.723315
[115]	validation_0-auc:0.859371	validation_1-auc:0.724403
[116]	validation_0-auc:0.859888	validation_1-auc:0.724399
[117]	validation_0-auc:0.860933	validation_1-auc:0.724632
[118]	validation_0-auc:0.861791	validation_1-auc:0.725889
[119]	validation_0-auc:0.864299	validation_1-auc:0.723144
[120]	validation_0-auc:0.866401	validation_1-auc:0.724979
[121]	validation_0-auc:0.867501	validation_1-auc:0.724934
[122]	validation_0-auc:0.867829	validation_1-auc:0.725608
[123]	validation_0-auc:0.868136	validation_1-auc:0.724913
[124]	validation_0-auc:0.86857	validation_1-auc:0.72477
[125]	validation_0-auc:0.868957	validation_1-auc:0.724595
[126]	validation_0-auc:0.870467	validation_1-auc:0.726657
[127]	validation_0-auc:0.87186	validation_1-auc:0.726695
[128]	validation_0-auc:0.872195	validation_1-auc:0.726227
[129]	validation_0-auc:0.87245	validation_1-auc:0.726353
[130]	validation_0-auc:0.874117	validation_1-auc:0.724956
[131]	validation_0-auc:0.874647	validation_1-auc:0.724923
[132]	validation_0-auc:0.875885	validation_1-auc:0.726653
[133]	validation_0-auc:0.877107	validation_1-auc:0.725447
[134]	validation_0-auc:0.878185	validation_1-auc:0.725657
[135]	validation_0-auc:0.878356	validation_1-auc:0.726241
[136]	validation_0-auc:0.878938	validation_1-auc:0.727792
[137]	validation_0-auc:0.87927	validation_1-auc:0.728354
[138]	validation_0-auc:0.880927	validation_1-auc:0.72959
[139]	validation_0-auc:0.880928	validation_1-auc:0.729784
[140]	validation_0-auc:0.882194	validation_1-auc:0.729406
[141]	validation_0-auc:0.882289	validation_1-auc:0.729173
[142]	validation_0-auc:0.883399	validation_1-auc:0.729266
[143]	validation_0-auc:0.884305	validation_1-auc:0.731691
[144]	validation_0-auc:0.884538	validation_1-auc:0.73133
[145]	validation_0-auc:0.886202	validation_1-auc:0.730827
[146]	validation_0-auc:0.887551	validation_1-auc:0.734282
[147]	validation_0-auc:0.888951	validation_1-auc:0.734555
[148]	validation_0-auc:0.890355	validation_1-auc:0.733535
[149]	validation_0-auc:0.891798	validation_1-auc:0.732633
[150]	validation_0-auc:0.892547	validation_1-auc:0.732933
[151]	validation_0-auc:0.892783	validation_1-auc:0.731975
[152]	validation_0-auc:0.892777	validation_1-auc:0.731497
[153]	validation_0-auc:0.893003	validation_1-auc:0.73171
[154]	validation_0-auc:0.893263	validation_1-auc:0.731978
[155]	validation_0-auc:0.894946	validation_1-auc:0.733314
[156]	validation_0-auc:0.89642	validation_1-auc:0.733833
[157]	validation_0-auc:0.896789	validation_1-auc:0.733617
[158]	validation_0-auc:0.897053	validation_1-auc:0.733111
[159]	validation_0-auc:0.897254	validation_1-auc:0.733064
[160]	validation_0-auc:0.898104	validation_1-auc:0.733556
[161]	validation_0-auc:0.898367	validation_1-auc:0.732437
[162]	validation_0-auc:0.898432	validation_1-auc:0.732556
[163]	validation_0-auc:0.899184	validation_1-auc:0.731849
[164]	validation_0-auc:0.899813	validation_1-auc:0.733261
[165]	validation_0-auc:0.900117	validation_1-auc:0.73341
[166]	validation_0-auc:0.901496	validation_1-auc:0.734841
[167]	validation_0-auc:0.901726	validation_1-auc:0.734383
[168]	validation_0-auc:0.901885	validation_1-auc:0.734455
[169]	validation_0-auc:0.90232	validation_1-auc:0.734724
[170]	validation_0-auc:0.904499	validation_1-auc:0.735176
[171]	validation_0-auc:0.904613	validation_1-auc:0.735465
[172]	validation_0-auc:0.905847	validation_1-auc:0.735258
[173]	validation_0-auc:0.905943	validation_1-auc:0.73409
[174]	validation_0-auc:0.906297	validation_1-auc:0.734706
[175]	validation_0-auc:0.906224	validation_1-auc:0.734495
[176]	validation_0-auc:0.908028	validation_1-auc:0.73471
[177]	validation_0-auc:0.908371	validation_1-auc:0.735699
[178]	validation_0-auc:0.908601	validation_1-auc:0.735849
[179]	validation_0-auc:0.909052	validation_1-auc:0.735288
[180]	validation_0-auc:0.909573	validation_1-auc:0.735834
[181]	validation_0-auc:0.910695	validation_1-auc:0.736907
[182]	validation_0-auc:0.91112	validation_1-auc:0.736858
[183]	validation_0-auc:0.912156	validation_1-auc:0.737725
[184]	validation_0-auc:0.912262	validation_1-auc:0.73778
[185]	validation_0-auc:0.913005	validation_1-auc:0.737682
[186]	validation_0-auc:0.913052	validation_1-auc:0.737547
[187]	validation_0-auc:0.913403	validation_1-auc:0.737207
[188]	validation_0-auc:0.91406	validation_1-auc:0.737809
[189]	validation_0-auc:0.914151	validation_1-auc:0.738652
[190]	validation_0-auc:0.914237	validation_1-auc:0.738881
[191]	validation_0-auc:0.914462	validation_1-auc:0.738213
[192]	validation_0-auc:0.914726	validation_1-auc:0.73776
[193]	validation_0-auc:0.915389	validation_1-auc:0.738097
[194]	validation_0-auc:0.91571	validation_1-auc:0.73789
[195]	validation_0-auc:0.915966	validation_1-auc:0.738528
[196]	validation_0-auc:0.917788	validation_1-auc:0.73826
[197]	validation_0-auc:0.917904	validation_1-auc:0.737053
[198]	validation_0-auc:0.918035	validation_1-auc:0.739028
[199]	validation_0-auc:0.918662	validation_1-auc:0.738724
0.7390284685302692
-------------------------------------------------------------------------------------------------
Fold 2
[0]	validation_0-auc:0.573939	validation_1-auc:0.598789
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.638814	validation_1-auc:0.661655
[2]	validation_0-auc:0.638814	validation_1-auc:0.661655
[3]	validation_0-auc:0.638814	validation_1-auc:0.661655
[4]	validation_0-auc:0.639685	validation_1-auc:0.661579
[5]	validation_0-auc:0.639792	validation_1-auc:0.661537
[6]	validation_0-auc:0.641603	validation_1-auc:0.663772
[7]	validation_0-auc:0.648956	validation_1-auc:0.674499
[8]	validation_0-auc:0.654195	validation_1-auc:0.679203
[9]	validation_0-auc:0.656827	validation_1-auc:0.681939
[10]	validation_0-auc:0.658848	validation_1-auc:0.683519
[11]	validation_0-auc:0.661033	validation_1-auc:0.684215
[12]	validation_0-auc:0.664678	validation_1-auc:0.684673
[13]	validation_0-auc:0.66477	validation_1-auc:0.68594
[14]	validation_0-auc:0.666543	validation_1-auc:0.686678
[15]	validation_0-auc:0.666554	validation_1-auc:0.68713
[16]	validation_0-auc:0.669437	validation_1-auc:0.686432
[17]	validation_0-auc:0.670975	validation_1-auc:0.686678
[18]	validation_0-auc:0.674088	validation_1-auc:0.685637
[19]	validation_0-auc:0.675391	validation_1-auc:0.687
[20]	validation_0-auc:0.68858	validation_1-auc:0.703461
[21]	validation_0-auc:0.689625	validation_1-auc:0.702984
[22]	validation_0-auc:0.690968	validation_1-auc:0.702872
[23]	validation_0-auc:0.69186	validation_1-auc:0.703143
[24]	validation_0-auc:0.693429	validation_1-auc:0.702142
[25]	validation_0-auc:0.700223	validation_1-auc:0.703853
[26]	validation_0-auc:0.700685	validation_1-auc:0.702605
[27]	validation_0-auc:0.7035	validation_1-auc:0.704511
[28]	validation_0-auc:0.70619	validation_1-auc:0.706735
[29]	validation_0-auc:0.708134	validation_1-auc:0.707079
[30]	validation_0-auc:0.710095	validation_1-auc:0.707903
[31]	validation_0-auc:0.713103	validation_1-auc:0.707939
[32]	validation_0-auc:0.720035	validation_1-auc:0.719185
[33]	validation_0-auc:0.720539	validation_1-auc:0.719372
[34]	validation_0-auc:0.722115	validation_1-auc:0.718209
[35]	validation_0-auc:0.72349	validation_1-auc:0.718985
[36]	validation_0-auc:0.730781	validation_1-auc:0.713995
[37]	validation_0-auc:0.731258	validation_1-auc:0.718612
[38]	validation_0-auc:0.733615	validation_1-auc:0.718905
[39]	validation_0-auc:0.738118	validation_1-auc:0.721257
[40]	validation_0-auc:0.74014	validation_1-auc:0.721281
[41]	validation_0-auc:0.743224	validation_1-auc:0.72308
[42]	validation_0-auc:0.746843	validation_1-auc:0.725244
[43]	validation_0-auc:0.749123	validation_1-auc:0.727075
[44]	validation_0-auc:0.753214	validation_1-auc:0.72543
[45]	validation_0-auc:0.755008	validation_1-auc:0.725076
[46]	validation_0-auc:0.757981	validation_1-auc:0.725066
[47]	validation_0-auc:0.762353	validation_1-auc:0.727305
[48]	validation_0-auc:0.766869	validation_1-auc:0.726262
[49]	validation_0-auc:0.76823	validation_1-auc:0.726649
[50]	validation_0-auc:0.770097	validation_1-auc:0.728511
[51]	validation_0-auc:0.773867	validation_1-auc:0.730984
[52]	validation_0-auc:0.776895	validation_1-auc:0.729778
[53]	validation_0-auc:0.780477	validation_1-auc:0.729158
[54]	validation_0-auc:0.782671	validation_1-auc:0.730767
[55]	validation_0-auc:0.784732	validation_1-auc:0.73094
[56]	validation_0-auc:0.787925	validation_1-auc:0.733938
[57]	validation_0-auc:0.789325	validation_1-auc:0.734029
[58]	validation_0-auc:0.791399	validation_1-auc:0.734116
[59]	validation_0-auc:0.794307	validation_1-auc:0.731245
[60]	validation_0-auc:0.79517	validation_1-auc:0.73153
[61]	validation_0-auc:0.795714	validation_1-auc:0.731094
[62]	validation_0-auc:0.798081	validation_1-auc:0.731534
[63]	validation_0-auc:0.799087	validation_1-auc:0.73196
[64]	validation_0-auc:0.799625	validation_1-auc:0.730132
[65]	validation_0-auc:0.803057	validation_1-auc:0.731727
[66]	validation_0-auc:0.805123	validation_1-auc:0.731951
[67]	validation_0-auc:0.805742	validation_1-auc:0.732247
[68]	validation_0-auc:0.808306	validation_1-auc:0.735165
[69]	validation_0-auc:0.809635	validation_1-auc:0.733678
[70]	validation_0-auc:0.811674	validation_1-auc:0.734738
[71]	validation_0-auc:0.813599	validation_1-auc:0.735423
[72]	validation_0-auc:0.815119	validation_1-auc:0.73395
[73]	validation_0-auc:0.817839	validation_1-auc:0.73531
[74]	validation_0-auc:0.819525	validation_1-auc:0.732358
[75]	validation_0-auc:0.820076	validation_1-auc:0.732635
[76]	validation_0-auc:0.820937	validation_1-auc:0.732437
[77]	validation_0-auc:0.822272	validation_1-auc:0.733254
[78]	validation_0-auc:0.823257	validation_1-auc:0.73319
[79]	validation_0-auc:0.824293	validation_1-auc:0.733815
[80]	validation_0-auc:0.82551	validation_1-auc:0.73335
[81]	validation_0-auc:0.828462	validation_1-auc:0.729773
[82]	validation_0-auc:0.831105	validation_1-auc:0.730849
[83]	validation_0-auc:0.832424	validation_1-auc:0.731242
[84]	validation_0-auc:0.833441	validation_1-auc:0.7308
[85]	validation_0-auc:0.834396	validation_1-auc:0.73243
[86]	validation_0-auc:0.836062	validation_1-auc:0.732292
[87]	validation_0-auc:0.837643	validation_1-auc:0.732066
[88]	validation_0-auc:0.8383	validation_1-auc:0.732163
[89]	validation_0-auc:0.838798	validation_1-auc:0.731475
[90]	validation_0-auc:0.839415	validation_1-auc:0.731655
[91]	validation_0-auc:0.84145	validation_1-auc:0.731058
[92]	validation_0-auc:0.843283	validation_1-auc:0.732602
[93]	validation_0-auc:0.843488	validation_1-auc:0.732191
[94]	validation_0-auc:0.844087	validation_1-auc:0.731939
[95]	validation_0-auc:0.84449	validation_1-auc:0.732448
[96]	validation_0-auc:0.845645	validation_1-auc:0.732791
[97]	validation_0-auc:0.845774	validation_1-auc:0.73282
[98]	validation_0-auc:0.846391	validation_1-auc:0.733276
[99]	validation_0-auc:0.847517	validation_1-auc:0.733748
[100]	validation_0-auc:0.848421	validation_1-auc:0.73424
[101]	validation_0-auc:0.849272	validation_1-auc:0.733467
[102]	validation_0-auc:0.851627	validation_1-auc:0.733251
[103]	validation_0-auc:0.852366	validation_1-auc:0.733113
[104]	validation_0-auc:0.853577	validation_1-auc:0.732225
[105]	validation_0-auc:0.854865	validation_1-auc:0.731759
[106]	validation_0-auc:0.856183	validation_1-auc:0.732205
[107]	validation_0-auc:0.856825	validation_1-auc:0.732454
[108]	validation_0-auc:0.858675	validation_1-auc:0.733386
[109]	validation_0-auc:0.860036	validation_1-auc:0.731968
[110]	validation_0-auc:0.861043	validation_1-auc:0.730476
[111]	validation_0-auc:0.861511	validation_1-auc:0.730241
[112]	validation_0-auc:0.863242	validation_1-auc:0.728449
[113]	validation_0-auc:0.865704	validation_1-auc:0.728007
[114]	validation_0-auc:0.866096	validation_1-auc:0.728578
[115]	validation_0-auc:0.867497	validation_1-auc:0.729219
[116]	validation_0-auc:0.86806	validation_1-auc:0.727622
[117]	validation_0-auc:0.869034	validation_1-auc:0.728249
[118]	validation_0-auc:0.870483	validation_1-auc:0.730666
[119]	validation_0-auc:0.871287	validation_1-auc:0.728905
[120]	validation_0-auc:0.872211	validation_1-auc:0.728836
[121]	validation_0-auc:0.872689	validation_1-auc:0.729099
[122]	validation_0-auc:0.872876	validation_1-auc:0.728902
[123]	validation_0-auc:0.873327	validation_1-auc:0.729831
[124]	validation_0-auc:0.873657	validation_1-auc:0.72971
[125]	validation_0-auc:0.874011	validation_1-auc:0.729063
[126]	validation_0-auc:0.874821	validation_1-auc:0.728011
[127]	validation_0-auc:0.875156	validation_1-auc:0.72808
[128]	validation_0-auc:0.875587	validation_1-auc:0.727919
[129]	validation_0-auc:0.876289	validation_1-auc:0.727261
[130]	validation_0-auc:0.877478	validation_1-auc:0.730849
[131]	validation_0-auc:0.878651	validation_1-auc:0.731092
[132]	validation_0-auc:0.878793	validation_1-auc:0.729593
[133]	validation_0-auc:0.879442	validation_1-auc:0.729451
[134]	validation_0-auc:0.880298	validation_1-auc:0.72952
[135]	validation_0-auc:0.880448	validation_1-auc:0.729592
[136]	validation_0-auc:0.880856	validation_1-auc:0.729886
[137]	validation_0-auc:0.881382	validation_1-auc:0.730807
[138]	validation_0-auc:0.881975	validation_1-auc:0.731417
[139]	validation_0-auc:0.8833	validation_1-auc:0.72958
[140]	validation_0-auc:0.884346	validation_1-auc:0.728881
[141]	validation_0-auc:0.884451	validation_1-auc:0.72871
[142]	validation_0-auc:0.885243	validation_1-auc:0.72791
[143]	validation_0-auc:0.885562	validation_1-auc:0.728091
[144]	validation_0-auc:0.886777	validation_1-auc:0.72727
[145]	validation_0-auc:0.887567	validation_1-auc:0.729103
[146]	validation_0-auc:0.887826	validation_1-auc:0.730276
[147]	validation_0-auc:0.889355	validation_1-auc:0.729417
[148]	validation_0-auc:0.889431	validation_1-auc:0.729014
[149]	validation_0-auc:0.889645	validation_1-auc:0.729409
[150]	validation_0-auc:0.890056	validation_1-auc:0.729121
[151]	validation_0-auc:0.890671	validation_1-auc:0.729081
[152]	validation_0-auc:0.891032	validation_1-auc:0.728603
[153]	validation_0-auc:0.891452	validation_1-auc:0.727998
[154]	validation_0-auc:0.892288	validation_1-auc:0.727801
[155]	validation_0-auc:0.892716	validation_1-auc:0.727636
[156]	validation_0-auc:0.89282	validation_1-auc:0.726771
[157]	validation_0-auc:0.893033	validation_1-auc:0.727463
[158]	validation_0-auc:0.893817	validation_1-auc:0.727531
[159]	validation_0-auc:0.893915	validation_1-auc:0.727326
[160]	validation_0-auc:0.89531	validation_1-auc:0.728022
[161]	validation_0-auc:0.895999	validation_1-auc:0.727994
[162]	validation_0-auc:0.897496	validation_1-auc:0.729141
[163]	validation_0-auc:0.898739	validation_1-auc:0.729448
[164]	validation_0-auc:0.899617	validation_1-auc:0.728918
[165]	validation_0-auc:0.899862	validation_1-auc:0.729149
[166]	validation_0-auc:0.900369	validation_1-auc:0.727243
[167]	validation_0-auc:0.901923	validation_1-auc:0.725742
[168]	validation_0-auc:0.902035	validation_1-auc:0.726057
[169]	validation_0-auc:0.902244	validation_1-auc:0.72631
[170]	validation_0-auc:0.903195	validation_1-auc:0.725806
[171]	validation_0-auc:0.90325	validation_1-auc:0.725573
[172]	validation_0-auc:0.903671	validation_1-auc:0.726129
[173]	validation_0-auc:0.905227	validation_1-auc:0.724749
[174]	validation_0-auc:0.906102	validation_1-auc:0.723521
[175]	validation_0-auc:0.906934	validation_1-auc:0.723681
[176]	validation_0-auc:0.907072	validation_1-auc:0.723521
[177]	validation_0-auc:0.907305	validation_1-auc:0.723569
[178]	validation_0-auc:0.907403	validation_1-auc:0.723597
[179]	validation_0-auc:0.907585	validation_1-auc:0.7239
[180]	validation_0-auc:0.907493	validation_1-auc:0.723675
[181]	validation_0-auc:0.908384	validation_1-auc:0.723295
[182]	validation_0-auc:0.908486	validation_1-auc:0.723606
[183]	validation_0-auc:0.909178	validation_1-auc:0.723697
[184]	validation_0-auc:0.90969	validation_1-auc:0.72373
[185]	validation_0-auc:0.910329	validation_1-auc:0.72252
[186]	validation_0-auc:0.91095	validation_1-auc:0.72126
[187]	validation_0-auc:0.911171	validation_1-auc:0.721354
[188]	validation_0-auc:0.911579	validation_1-auc:0.720665
[189]	validation_0-auc:0.911748	validation_1-auc:0.720731
[190]	validation_0-auc:0.912076	validation_1-auc:0.719669
[191]	validation_0-auc:0.912252	validation_1-auc:0.719314
[192]	validation_0-auc:0.912534	validation_1-auc:0.720056
[193]	validation_0-auc:0.912683	validation_1-auc:0.718622
[194]	validation_0-auc:0.913287	validation_1-auc:0.719082
[195]	validation_0-auc:0.914253	validation_1-auc:0.717526
[196]	validation_0-auc:0.915011	validation_1-auc:0.718531
[197]	validation_0-auc:0.915308	validation_1-auc:0.718707
[198]	validation_0-auc:0.915408	validation_1-auc:0.718927
[199]	validation_0-auc:0.915511	validation_1-auc:0.718977
0.7354232764534385
-------------------------------------------------------------------------------------------------
Fold 3
[0]	validation_0-auc:0.571075	validation_1-auc:0.624505
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.636341	validation_1-auc:0.683806
[2]	validation_0-auc:0.636341	validation_1-auc:0.683806
[3]	validation_0-auc:0.636341	validation_1-auc:0.683806
[4]	validation_0-auc:0.637212	validation_1-auc:0.683806
[5]	validation_0-auc:0.639137	validation_1-auc:0.685207
[6]	validation_0-auc:0.648153	validation_1-auc:0.688018
[7]	validation_0-auc:0.653371	validation_1-auc:0.689164
[8]	validation_0-auc:0.656787	validation_1-auc:0.686956
[9]	validation_0-auc:0.657879	validation_1-auc:0.691131
[10]	validation_0-auc:0.657941	validation_1-auc:0.691563
[11]	validation_0-auc:0.658849	validation_1-auc:0.691202
[12]	validation_0-auc:0.662961	validation_1-auc:0.690693
[13]	validation_0-auc:0.662861	validation_1-auc:0.690678
[14]	validation_0-auc:0.662984	validation_1-auc:0.685395
[15]	validation_0-auc:0.664518	validation_1-auc:0.686629
[16]	validation_0-auc:0.666091	validation_1-auc:0.687622
[17]	validation_0-auc:0.667628	validation_1-auc:0.687672
[18]	validation_0-auc:0.683604	validation_1-auc:0.689815
[19]	validation_0-auc:0.685243	validation_1-auc:0.690446
[20]	validation_0-auc:0.685498	validation_1-auc:0.689838
[21]	validation_0-auc:0.688176	validation_1-auc:0.696293
[22]	validation_0-auc:0.689446	validation_1-auc:0.695221
[23]	validation_0-auc:0.69235	validation_1-auc:0.696853
[24]	validation_0-auc:0.693257	validation_1-auc:0.699875
[25]	validation_0-auc:0.694947	validation_1-auc:0.697261
[26]	validation_0-auc:0.702457	validation_1-auc:0.706634
[27]	validation_0-auc:0.7022	validation_1-auc:0.70474
[28]	validation_0-auc:0.703152	validation_1-auc:0.704584
[29]	validation_0-auc:0.707049	validation_1-auc:0.709269
[30]	validation_0-auc:0.709403	validation_1-auc:0.713925
[31]	validation_0-auc:0.710024	validation_1-auc:0.710062
[32]	validation_0-auc:0.713446	validation_1-auc:0.711837
[33]	validation_0-auc:0.716346	validation_1-auc:0.711843
[34]	validation_0-auc:0.717738	validation_1-auc:0.709939
[35]	validation_0-auc:0.719737	validation_1-auc:0.71124
[36]	validation_0-auc:0.726549	validation_1-auc:0.720202
[37]	validation_0-auc:0.72906	validation_1-auc:0.727251
[38]	validation_0-auc:0.732862	validation_1-auc:0.729424
[39]	validation_0-auc:0.735877	validation_1-auc:0.736047
[40]	validation_0-auc:0.736727	validation_1-auc:0.734788
[41]	validation_0-auc:0.740727	validation_1-auc:0.739299
[42]	validation_0-auc:0.747656	validation_1-auc:0.741323
[43]	validation_0-auc:0.750367	validation_1-auc:0.740143
[44]	validation_0-auc:0.752093	validation_1-auc:0.740909
[45]	validation_0-auc:0.755432	validation_1-auc:0.744942
[46]	validation_0-auc:0.758587	validation_1-auc:0.74127
[47]	validation_0-auc:0.760955	validation_1-auc:0.74426
[48]	validation_0-auc:0.763365	validation_1-auc:0.742719
[49]	validation_0-auc:0.76585	validation_1-auc:0.74371
[50]	validation_0-auc:0.768314	validation_1-auc:0.746411
[51]	validation_0-auc:0.769243	validation_1-auc:0.744647
[52]	validation_0-auc:0.77156	validation_1-auc:0.743411
[53]	validation_0-auc:0.774448	validation_1-auc:0.745158
[54]	validation_0-auc:0.775795	validation_1-auc:0.746027
[55]	validation_0-auc:0.777535	validation_1-auc:0.744635
[56]	validation_0-auc:0.781487	validation_1-auc:0.747275
[57]	validation_0-auc:0.783856	validation_1-auc:0.747424
[58]	validation_0-auc:0.785979	validation_1-auc:0.746267
[59]	validation_0-auc:0.787055	validation_1-auc:0.745145
[60]	validation_0-auc:0.78889	validation_1-auc:0.746637
[61]	validation_0-auc:0.791038	validation_1-auc:0.748186
[62]	validation_0-auc:0.792392	validation_1-auc:0.748793
[63]	validation_0-auc:0.793912	validation_1-auc:0.748077
[64]	validation_0-auc:0.795766	validation_1-auc:0.748542
[65]	validation_0-auc:0.797289	validation_1-auc:0.751108
[66]	validation_0-auc:0.799693	validation_1-auc:0.751575
[67]	validation_0-auc:0.80241	validation_1-auc:0.75034
[68]	validation_0-auc:0.802899	validation_1-auc:0.750041
[69]	validation_0-auc:0.805067	validation_1-auc:0.748311
[70]	validation_0-auc:0.808833	validation_1-auc:0.748448
[71]	validation_0-auc:0.809356	validation_1-auc:0.748298
[72]	validation_0-auc:0.810336	validation_1-auc:0.74826
[73]	validation_0-auc:0.812699	validation_1-auc:0.74728
[74]	validation_0-auc:0.814466	validation_1-auc:0.746214
[75]	validation_0-auc:0.816434	validation_1-auc:0.744204
[76]	validation_0-auc:0.817279	validation_1-auc:0.744039
[77]	validation_0-auc:0.819298	validation_1-auc:0.744081
[78]	validation_0-auc:0.819808	validation_1-auc:0.744923
[79]	validation_0-auc:0.821783	validation_1-auc:0.745969
[80]	validation_0-auc:0.82488	validation_1-auc:0.746954
[81]	validation_0-auc:0.825991	validation_1-auc:0.745625
[82]	validation_0-auc:0.827556	validation_1-auc:0.744038
[83]	validation_0-auc:0.828008	validation_1-auc:0.745042
[84]	validation_0-auc:0.829342	validation_1-auc:0.74413
[85]	validation_0-auc:0.829703	validation_1-auc:0.744537
[86]	validation_0-auc:0.831447	validation_1-auc:0.745645
[87]	validation_0-auc:0.833395	validation_1-auc:0.746699
[88]	validation_0-auc:0.834683	validation_1-auc:0.746303
[89]	validation_0-auc:0.83726	validation_1-auc:0.746528
[90]	validation_0-auc:0.838545	validation_1-auc:0.746578
[91]	validation_0-auc:0.841117	validation_1-auc:0.747041
[92]	validation_0-auc:0.841947	validation_1-auc:0.745099
[93]	validation_0-auc:0.843123	validation_1-auc:0.744819
[94]	validation_0-auc:0.843602	validation_1-auc:0.744649
[95]	validation_0-auc:0.844036	validation_1-auc:0.744095
[96]	validation_0-auc:0.845557	validation_1-auc:0.744075
[97]	validation_0-auc:0.847372	validation_1-auc:0.744208
[98]	validation_0-auc:0.848983	validation_1-auc:0.746077
[99]	validation_0-auc:0.849586	validation_1-auc:0.744947
[100]	validation_0-auc:0.850471	validation_1-auc:0.745067
[101]	validation_0-auc:0.851326	validation_1-auc:0.745912
[102]	validation_0-auc:0.851776	validation_1-auc:0.745457
[103]	validation_0-auc:0.852324	validation_1-auc:0.745429
[104]	validation_0-auc:0.852601	validation_1-auc:0.745417
[105]	validation_0-auc:0.853506	validation_1-auc:0.745782
[106]	validation_0-auc:0.854341	validation_1-auc:0.744854
[107]	validation_0-auc:0.855267	validation_1-auc:0.744381
[108]	validation_0-auc:0.856312	validation_1-auc:0.74509
[109]	validation_0-auc:0.856777	validation_1-auc:0.745625
[110]	validation_0-auc:0.857542	validation_1-auc:0.74473
[111]	validation_0-auc:0.858065	validation_1-auc:0.746641
[112]	validation_0-auc:0.860282	validation_1-auc:0.745803
[113]	validation_0-auc:0.860919	validation_1-auc:0.745543
[114]	validation_0-auc:0.862246	validation_1-auc:0.746301
[115]	validation_0-auc:0.863925	validation_1-auc:0.745464
[116]	validation_0-auc:0.864032	validation_1-auc:0.745297
[117]	validation_0-auc:0.864381	validation_1-auc:0.745594
[118]	validation_0-auc:0.864978	validation_1-auc:0.744684
[119]	validation_0-auc:0.865169	validation_1-auc:0.744632
[120]	validation_0-auc:0.865341	validation_1-auc:0.744514
[121]	validation_0-auc:0.866191	validation_1-auc:0.744863
[122]	validation_0-auc:0.867983	validation_1-auc:0.744226
[123]	validation_0-auc:0.868547	validation_1-auc:0.744125
[124]	validation_0-auc:0.86948	validation_1-auc:0.743108
[125]	validation_0-auc:0.870817	validation_1-auc:0.7442
[126]	validation_0-auc:0.871271	validation_1-auc:0.743062
[127]	validation_0-auc:0.87196	validation_1-auc:0.743448
[128]	validation_0-auc:0.872486	validation_1-auc:0.74268
[129]	validation_0-auc:0.873106	validation_1-auc:0.743761
[130]	validation_0-auc:0.873301	validation_1-auc:0.743227
[131]	validation_0-auc:0.874181	validation_1-auc:0.742554
[132]	validation_0-auc:0.875932	validation_1-auc:0.742553
[133]	validation_0-auc:0.877389	validation_1-auc:0.740852
[134]	validation_0-auc:0.877922	validation_1-auc:0.741021
[135]	validation_0-auc:0.878449	validation_1-auc:0.74189
[136]	validation_0-auc:0.878646	validation_1-auc:0.74136
[137]	validation_0-auc:0.879794	validation_1-auc:0.741559
[138]	validation_0-auc:0.879912	validation_1-auc:0.741821
[139]	validation_0-auc:0.881268	validation_1-auc:0.742843
[140]	validation_0-auc:0.881775	validation_1-auc:0.742269
[141]	validation_0-auc:0.882225	validation_1-auc:0.742546
[142]	validation_0-auc:0.883701	validation_1-auc:0.742791
[143]	validation_0-auc:0.884633	validation_1-auc:0.743084
[144]	validation_0-auc:0.885869	validation_1-auc:0.742185
[145]	validation_0-auc:0.886105	validation_1-auc:0.742247
[146]	validation_0-auc:0.886237	validation_1-auc:0.74233
[147]	validation_0-auc:0.886644	validation_1-auc:0.742085
[148]	validation_0-auc:0.886892	validation_1-auc:0.742778
[149]	validation_0-auc:0.887072	validation_1-auc:0.7431
[150]	validation_0-auc:0.888181	validation_1-auc:0.743022
[151]	validation_0-auc:0.88893	validation_1-auc:0.742879
[152]	validation_0-auc:0.889069	validation_1-auc:0.742568
[153]	validation_0-auc:0.889202	validation_1-auc:0.743258
[154]	validation_0-auc:0.889357	validation_1-auc:0.743275
[155]	validation_0-auc:0.890527	validation_1-auc:0.742379
[156]	validation_0-auc:0.891297	validation_1-auc:0.741099
[157]	validation_0-auc:0.891552	validation_1-auc:0.74088
[158]	validation_0-auc:0.893255	validation_1-auc:0.741045
[159]	validation_0-auc:0.893829	validation_1-auc:0.741283
[160]	validation_0-auc:0.894605	validation_1-auc:0.740266
[161]	validation_0-auc:0.89508	validation_1-auc:0.740658
[162]	validation_0-auc:0.895658	validation_1-auc:0.738899
[163]	validation_0-auc:0.896194	validation_1-auc:0.739192
[164]	validation_0-auc:0.896812	validation_1-auc:0.738324
[165]	validation_0-auc:0.897995	validation_1-auc:0.738931
[166]	validation_0-auc:0.898666	validation_1-auc:0.738333
[167]	validation_0-auc:0.898919	validation_1-auc:0.737891
[168]	validation_0-auc:0.898982	validation_1-auc:0.737686
[169]	validation_0-auc:0.900071	validation_1-auc:0.737577
[170]	validation_0-auc:0.900376	validation_1-auc:0.737416
[171]	validation_0-auc:0.900492	validation_1-auc:0.738271
[172]	validation_0-auc:0.900602	validation_1-auc:0.738312
[173]	validation_0-auc:0.901143	validation_1-auc:0.737151
[174]	validation_0-auc:0.902282	validation_1-auc:0.738678
[175]	validation_0-auc:0.903692	validation_1-auc:0.73708
[176]	validation_0-auc:0.904434	validation_1-auc:0.735692
[177]	validation_0-auc:0.904643	validation_1-auc:0.735662
[178]	validation_0-auc:0.904653	validation_1-auc:0.736396
[179]	validation_0-auc:0.904801	validation_1-auc:0.736543
[180]	validation_0-auc:0.905082	validation_1-auc:0.735817
[181]	validation_0-auc:0.905878	validation_1-auc:0.736167
[182]	validation_0-auc:0.906317	validation_1-auc:0.735398
[183]	validation_0-auc:0.907628	validation_1-auc:0.735677
[184]	validation_0-auc:0.907929	validation_1-auc:0.736382
[185]	validation_0-auc:0.908024	validation_1-auc:0.736555
[186]	validation_0-auc:0.908438	validation_1-auc:0.735841
[187]	validation_0-auc:0.909076	validation_1-auc:0.734973
[188]	validation_0-auc:0.90983	validation_1-auc:0.735819
[189]	validation_0-auc:0.911081	validation_1-auc:0.73572
[190]	validation_0-auc:0.911336	validation_1-auc:0.73514
[191]	validation_0-auc:0.911682	validation_1-auc:0.734492
[192]	validation_0-auc:0.912076	validation_1-auc:0.735093
[193]	validation_0-auc:0.912227	validation_1-auc:0.735064
[194]	validation_0-auc:0.91265	validation_1-auc:0.735676
[195]	validation_0-auc:0.91271	validation_1-auc:0.735745
[196]	validation_0-auc:0.912851	validation_1-auc:0.735124
[197]	validation_0-auc:0.913206	validation_1-auc:0.734774
[198]	validation_0-auc:0.913322	validation_1-auc:0.734887
[199]	validation_0-auc:0.913666	validation_1-auc:0.734622
0.7515750943234436
-------------------------------------------------------------------------------------------------
Fold 4
[0]	validation_0-auc:0.57606	validation_1-auc:0.579764
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.639786	validation_1-auc:0.653118
[2]	validation_0-auc:0.639786	validation_1-auc:0.653118
[3]	validation_0-auc:0.640657	validation_1-auc:0.653118
[4]	validation_0-auc:0.657654	validation_1-auc:0.649614
[5]	validation_0-auc:0.657654	validation_1-auc:0.649614
[6]	validation_0-auc:0.661307	validation_1-auc:0.652461
[7]	validation_0-auc:0.661806	validation_1-auc:0.652493
[8]	validation_0-auc:0.665467	validation_1-auc:0.651888
[9]	validation_0-auc:0.666271	validation_1-auc:0.651808
[10]	validation_0-auc:0.667787	validation_1-auc:0.651812
[11]	validation_0-auc:0.668647	validation_1-auc:0.652298
[12]	validation_0-auc:0.670205	validation_1-auc:0.650962
[13]	validation_0-auc:0.671925	validation_1-auc:0.65094
[14]	validation_0-auc:0.674282	validation_1-auc:0.653032
[15]	validation_0-auc:0.674394	validation_1-auc:0.653084
[16]	validation_0-auc:0.675068	validation_1-auc:0.653617
[17]	validation_0-auc:0.676826	validation_1-auc:0.654907
[18]	validation_0-auc:0.678652	validation_1-auc:0.656985
[19]	validation_0-auc:0.67858	validation_1-auc:0.65661
[20]	validation_0-auc:0.679104	validation_1-auc:0.656281
[21]	validation_0-auc:0.679601	validation_1-auc:0.656636
[22]	validation_0-auc:0.688665	validation_1-auc:0.67254
[23]	validation_0-auc:0.689755	validation_1-auc:0.67265
[24]	validation_0-auc:0.694574	validation_1-auc:0.670383
[25]	validation_0-auc:0.696937	validation_1-auc:0.670199
[26]	validation_0-auc:0.698515	validation_1-auc:0.672773
[27]	validation_0-auc:0.700355	validation_1-auc:0.673597
[28]	validation_0-auc:0.704492	validation_1-auc:0.672755
[29]	validation_0-auc:0.706739	validation_1-auc:0.673067
[30]	validation_0-auc:0.709663	validation_1-auc:0.677701
[31]	validation_0-auc:0.711941	validation_1-auc:0.67787
[32]	validation_0-auc:0.714617	validation_1-auc:0.67963
[33]	validation_0-auc:0.718815	validation_1-auc:0.680381
[34]	validation_0-auc:0.721225	validation_1-auc:0.688063
[35]	validation_0-auc:0.722692	validation_1-auc:0.686307
[36]	validation_0-auc:0.723682	validation_1-auc:0.687515
[37]	validation_0-auc:0.725482	validation_1-auc:0.689238
[38]	validation_0-auc:0.727759	validation_1-auc:0.689538
[39]	validation_0-auc:0.729355	validation_1-auc:0.686914
[40]	validation_0-auc:0.732953	validation_1-auc:0.688557
[41]	validation_0-auc:0.736878	validation_1-auc:0.688108
[42]	validation_0-auc:0.744817	validation_1-auc:0.688923
[43]	validation_0-auc:0.748657	validation_1-auc:0.690649
[44]	validation_0-auc:0.750899	validation_1-auc:0.693977
[45]	validation_0-auc:0.753264	validation_1-auc:0.69425
[46]	validation_0-auc:0.756945	validation_1-auc:0.698373
[47]	validation_0-auc:0.759865	validation_1-auc:0.698609
[48]	validation_0-auc:0.762702	validation_1-auc:0.700847
[49]	validation_0-auc:0.765074	validation_1-auc:0.702102
[50]	validation_0-auc:0.767221	validation_1-auc:0.702139
[51]	validation_0-auc:0.770516	validation_1-auc:0.70197
[52]	validation_0-auc:0.772276	validation_1-auc:0.704493
[53]	validation_0-auc:0.775881	validation_1-auc:0.704009
[54]	validation_0-auc:0.778477	validation_1-auc:0.704759
[55]	validation_0-auc:0.781373	validation_1-auc:0.706151
[56]	validation_0-auc:0.783027	validation_1-auc:0.708387
[57]	validation_0-auc:0.785576	validation_1-auc:0.709851
[58]	validation_0-auc:0.787551	validation_1-auc:0.715315
[59]	validation_0-auc:0.790505	validation_1-auc:0.715483
[60]	validation_0-auc:0.792495	validation_1-auc:0.719203
[61]	validation_0-auc:0.793429	validation_1-auc:0.719979
[62]	validation_0-auc:0.794935	validation_1-auc:0.724509
[63]	validation_0-auc:0.796081	validation_1-auc:0.723254
[64]	validation_0-auc:0.797966	validation_1-auc:0.720139
[65]	validation_0-auc:0.798903	validation_1-auc:0.721223
[66]	validation_0-auc:0.800841	validation_1-auc:0.720535
[67]	validation_0-auc:0.803548	validation_1-auc:0.721908
[68]	validation_0-auc:0.803959	validation_1-auc:0.722615
[69]	validation_0-auc:0.805335	validation_1-auc:0.722026
[70]	validation_0-auc:0.807326	validation_1-auc:0.723345
[71]	validation_0-auc:0.810137	validation_1-auc:0.724022
[72]	validation_0-auc:0.812041	validation_1-auc:0.723854
[73]	validation_0-auc:0.812951	validation_1-auc:0.723494
[74]	validation_0-auc:0.813967	validation_1-auc:0.723736
[75]	validation_0-auc:0.814632	validation_1-auc:0.724508
[76]	validation_0-auc:0.817207	validation_1-auc:0.725452
[77]	validation_0-auc:0.817583	validation_1-auc:0.726357
[78]	validation_0-auc:0.819257	validation_1-auc:0.72489
[79]	validation_0-auc:0.820637	validation_1-auc:0.724005
[80]	validation_0-auc:0.822492	validation_1-auc:0.725435
[81]	validation_0-auc:0.822917	validation_1-auc:0.725698
[82]	validation_0-auc:0.823624	validation_1-auc:0.725762
[83]	validation_0-auc:0.824844	validation_1-auc:0.725392
[84]	validation_0-auc:0.826842	validation_1-auc:0.725968
[85]	validation_0-auc:0.827933	validation_1-auc:0.726385
[86]	validation_0-auc:0.829356	validation_1-auc:0.726648
[87]	validation_0-auc:0.831043	validation_1-auc:0.726331
[88]	validation_0-auc:0.8318	validation_1-auc:0.727247
[89]	validation_0-auc:0.832894	validation_1-auc:0.727406
[90]	validation_0-auc:0.834317	validation_1-auc:0.725233
[91]	validation_0-auc:0.834354	validation_1-auc:0.724952
[92]	validation_0-auc:0.835054	validation_1-auc:0.72411
[93]	validation_0-auc:0.836244	validation_1-auc:0.72323
[94]	validation_0-auc:0.836485	validation_1-auc:0.723376
[95]	validation_0-auc:0.837571	validation_1-auc:0.724352
[96]	validation_0-auc:0.838339	validation_1-auc:0.727914
[97]	validation_0-auc:0.839776	validation_1-auc:0.727879
[98]	validation_0-auc:0.841988	validation_1-auc:0.727214
[99]	validation_0-auc:0.842882	validation_1-auc:0.726475
[100]	validation_0-auc:0.843132	validation_1-auc:0.726677
[101]	validation_0-auc:0.846986	validation_1-auc:0.722473
[102]	validation_0-auc:0.847655	validation_1-auc:0.722896
[103]	validation_0-auc:0.848175	validation_1-auc:0.722461
[104]	validation_0-auc:0.850295	validation_1-auc:0.724732
[105]	validation_0-auc:0.852625	validation_1-auc:0.72464
[106]	validation_0-auc:0.853113	validation_1-auc:0.725477
[107]	validation_0-auc:0.853534	validation_1-auc:0.723796
[108]	validation_0-auc:0.854104	validation_1-auc:0.725023
[109]	validation_0-auc:0.855144	validation_1-auc:0.72965
[110]	validation_0-auc:0.855465	validation_1-auc:0.729799
[111]	validation_0-auc:0.855856	validation_1-auc:0.728481
[112]	validation_0-auc:0.856488	validation_1-auc:0.728459
[113]	validation_0-auc:0.857409	validation_1-auc:0.726814
[114]	validation_0-auc:0.859421	validation_1-auc:0.726772
[115]	validation_0-auc:0.859994	validation_1-auc:0.727238
[116]	validation_0-auc:0.860812	validation_1-auc:0.72811
[117]	validation_0-auc:0.861529	validation_1-auc:0.729375
[118]	validation_0-auc:0.862767	validation_1-auc:0.729102
[119]	validation_0-auc:0.863076	validation_1-auc:0.729206
[120]	validation_0-auc:0.865164	validation_1-auc:0.725733
[121]	validation_0-auc:0.865467	validation_1-auc:0.725334
[122]	validation_0-auc:0.866674	validation_1-auc:0.726353
[123]	validation_0-auc:0.867644	validation_1-auc:0.726593
[124]	validation_0-auc:0.868164	validation_1-auc:0.726402
[125]	validation_0-auc:0.86861	validation_1-auc:0.726122
[126]	validation_0-auc:0.868508	validation_1-auc:0.726034
[127]	validation_0-auc:0.869227	validation_1-auc:0.727623
[128]	validation_0-auc:0.869865	validation_1-auc:0.731417
[129]	validation_0-auc:0.870749	validation_1-auc:0.733287
[130]	validation_0-auc:0.871451	validation_1-auc:0.732727
[131]	validation_0-auc:0.872482	validation_1-auc:0.732707
[132]	validation_0-auc:0.873639	validation_1-auc:0.732927
[133]	validation_0-auc:0.874391	validation_1-auc:0.732858
[134]	validation_0-auc:0.875398	validation_1-auc:0.731265
[135]	validation_0-auc:0.877109	validation_1-auc:0.730281
[136]	validation_0-auc:0.877392	validation_1-auc:0.730493
[137]	validation_0-auc:0.87812	validation_1-auc:0.730462
[138]	validation_0-auc:0.879315	validation_1-auc:0.730043
[139]	validation_0-auc:0.880816	validation_1-auc:0.727606
[140]	validation_0-auc:0.881688	validation_1-auc:0.727368
[141]	validation_0-auc:0.882326	validation_1-auc:0.727705
[142]	validation_0-auc:0.882467	validation_1-auc:0.727941
[143]	validation_0-auc:0.883608	validation_1-auc:0.726313
[144]	validation_0-auc:0.883861	validation_1-auc:0.727118
[145]	validation_0-auc:0.88481	validation_1-auc:0.726477
[146]	validation_0-auc:0.884885	validation_1-auc:0.726834
[147]	validation_0-auc:0.885179	validation_1-auc:0.726481
[148]	validation_0-auc:0.885897	validation_1-auc:0.726911
[149]	validation_0-auc:0.887128	validation_1-auc:0.72748
[150]	validation_0-auc:0.887977	validation_1-auc:0.727746
[151]	validation_0-auc:0.889167	validation_1-auc:0.727081
[152]	validation_0-auc:0.890209	validation_1-auc:0.727503
[153]	validation_0-auc:0.891867	validation_1-auc:0.729299
[154]	validation_0-auc:0.891975	validation_1-auc:0.730774
[155]	validation_0-auc:0.892031	validation_1-auc:0.7308
[156]	validation_0-auc:0.892682	validation_1-auc:0.730186
[157]	validation_0-auc:0.892777	validation_1-auc:0.730222
[158]	validation_0-auc:0.892848	validation_1-auc:0.730106
[159]	validation_0-auc:0.892964	validation_1-auc:0.730151
[160]	validation_0-auc:0.893054	validation_1-auc:0.729889
[161]	validation_0-auc:0.893707	validation_1-auc:0.728886
[162]	validation_0-auc:0.894524	validation_1-auc:0.728823
[163]	validation_0-auc:0.894934	validation_1-auc:0.729251
[164]	validation_0-auc:0.895812	validation_1-auc:0.729525
[165]	validation_0-auc:0.897123	validation_1-auc:0.732303
[166]	validation_0-auc:0.897938	validation_1-auc:0.730769
[167]	validation_0-auc:0.899032	validation_1-auc:0.7288
[168]	validation_0-auc:0.899202	validation_1-auc:0.729451
[169]	validation_0-auc:0.89931	validation_1-auc:0.728995
[170]	validation_0-auc:0.899973	validation_1-auc:0.727731
[171]	validation_0-auc:0.900277	validation_1-auc:0.72798
[172]	validation_0-auc:0.901552	validation_1-auc:0.727487
[173]	validation_0-auc:0.902663	validation_1-auc:0.727108
[174]	validation_0-auc:0.903678	validation_1-auc:0.726493
[175]	validation_0-auc:0.904381	validation_1-auc:0.726307
[176]	validation_0-auc:0.904856	validation_1-auc:0.725943
[177]	validation_0-auc:0.905162	validation_1-auc:0.726006
[178]	validation_0-auc:0.905246	validation_1-auc:0.726053
[179]	validation_0-auc:0.905346	validation_1-auc:0.726227
[180]	validation_0-auc:0.906426	validation_1-auc:0.72539
[181]	validation_0-auc:0.907076	validation_1-auc:0.725085
[182]	validation_0-auc:0.907523	validation_1-auc:0.724489
[183]	validation_0-auc:0.907592	validation_1-auc:0.723402
[184]	validation_0-auc:0.908204	validation_1-auc:0.722423
[185]	validation_0-auc:0.90909	validation_1-auc:0.721911
[186]	validation_0-auc:0.909817	validation_1-auc:0.723907
[187]	validation_0-auc:0.909954	validation_1-auc:0.723995
[188]	validation_0-auc:0.910502	validation_1-auc:0.723879
[189]	validation_0-auc:0.910641	validation_1-auc:0.725273
[190]	validation_0-auc:0.911323	validation_1-auc:0.724456
[191]	validation_0-auc:0.91148	validation_1-auc:0.723541
[192]	validation_0-auc:0.912551	validation_1-auc:0.725206
[193]	validation_0-auc:0.912729	validation_1-auc:0.724808
[194]	validation_0-auc:0.91287	validation_1-auc:0.725045
[195]	validation_0-auc:0.912898	validation_1-auc:0.724973
[196]	validation_0-auc:0.913404	validation_1-auc:0.724845
[197]	validation_0-auc:0.913769	validation_1-auc:0.724435
[198]	validation_0-auc:0.914593	validation_1-auc:0.724799
[199]	validation_0-auc:0.915771	validation_1-auc:0.725443
0.733286881950958
-------------------------------------------------------------------------------------------------
Fold 5
[0]	validation_0-auc:0.577297	validation_1-auc:0.568643
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.645439	validation_1-auc:0.602363
[2]	validation_0-auc:0.645439	validation_1-auc:0.602363
[3]	validation_0-auc:0.64631	validation_1-auc:0.602221
[4]	validation_0-auc:0.646522	validation_1-auc:0.602146
[5]	validation_0-auc:0.660423	validation_1-auc:0.601862
[6]	validation_0-auc:0.664441	validation_1-auc:0.602642
[7]	validation_0-auc:0.670462	validation_1-auc:0.602919
[8]	validation_0-auc:0.670678	validation_1-auc:0.601337
[9]	validation_0-auc:0.671979	validation_1-auc:0.601446
[10]	validation_0-auc:0.671833	validation_1-auc:0.60113
[11]	validation_0-auc:0.671754	validation_1-auc:0.601209
[12]	validation_0-auc:0.674436	validation_1-auc:0.600842
[13]	validation_0-auc:0.676342	validation_1-auc:0.601016
[14]	validation_0-auc:0.677823	validation_1-auc:0.600504
[15]	validation_0-auc:0.678592	validation_1-auc:0.600542
[16]	validation_0-auc:0.678966	validation_1-auc:0.600249
[17]	validation_0-auc:0.679651	validation_1-auc:0.599847
[18]	validation_0-auc:0.690929	validation_1-auc:0.60326
[19]	validation_0-auc:0.692446	validation_1-auc:0.603962
[20]	validation_0-auc:0.702664	validation_1-auc:0.61244
[21]	validation_0-auc:0.702503	validation_1-auc:0.613813
[22]	validation_0-auc:0.70322	validation_1-auc:0.613361
[23]	validation_0-auc:0.705364	validation_1-auc:0.613567
[24]	validation_0-auc:0.708102	validation_1-auc:0.618514
[25]	validation_0-auc:0.70903	validation_1-auc:0.619733
[26]	validation_0-auc:0.710637	validation_1-auc:0.620433
[27]	validation_0-auc:0.712212	validation_1-auc:0.621026
[28]	validation_0-auc:0.714369	validation_1-auc:0.620905
[29]	validation_0-auc:0.715643	validation_1-auc:0.621529
[30]	validation_0-auc:0.717914	validation_1-auc:0.625142
[31]	validation_0-auc:0.722005	validation_1-auc:0.625165
[32]	validation_0-auc:0.722766	validation_1-auc:0.6266
[33]	validation_0-auc:0.724273	validation_1-auc:0.626509
[34]	validation_0-auc:0.731355	validation_1-auc:0.62877
[35]	validation_0-auc:0.732212	validation_1-auc:0.628769
[36]	validation_0-auc:0.734917	validation_1-auc:0.630671
[37]	validation_0-auc:0.737068	validation_1-auc:0.629215
[38]	validation_0-auc:0.741001	validation_1-auc:0.625093
[39]	validation_0-auc:0.743989	validation_1-auc:0.625664
[40]	validation_0-auc:0.746329	validation_1-auc:0.624747
[41]	validation_0-auc:0.749611	validation_1-auc:0.627526
[42]	validation_0-auc:0.751222	validation_1-auc:0.628559
[43]	validation_0-auc:0.756873	validation_1-auc:0.625829
[44]	validation_0-auc:0.759544	validation_1-auc:0.627515
[45]	validation_0-auc:0.762156	validation_1-auc:0.629157
[46]	validation_0-auc:0.763914	validation_1-auc:0.631233
[47]	validation_0-auc:0.766328	validation_1-auc:0.629738
[48]	validation_0-auc:0.767713	validation_1-auc:0.631001
[49]	validation_0-auc:0.770058	validation_1-auc:0.63261
[50]	validation_0-auc:0.772087	validation_1-auc:0.63176
[51]	validation_0-auc:0.774603	validation_1-auc:0.629718
[52]	validation_0-auc:0.77736	validation_1-auc:0.627195
[53]	validation_0-auc:0.778953	validation_1-auc:0.626587
[54]	validation_0-auc:0.782254	validation_1-auc:0.628694
[55]	validation_0-auc:0.785504	validation_1-auc:0.631841
[56]	validation_0-auc:0.787767	validation_1-auc:0.634386
[57]	validation_0-auc:0.789343	validation_1-auc:0.636884
[58]	validation_0-auc:0.792716	validation_1-auc:0.638709
[59]	validation_0-auc:0.794191	validation_1-auc:0.641
[60]	validation_0-auc:0.79695	validation_1-auc:0.644121
[61]	validation_0-auc:0.797428	validation_1-auc:0.644613
[62]	validation_0-auc:0.798425	validation_1-auc:0.645743
[63]	validation_0-auc:0.799084	validation_1-auc:0.64618
[64]	validation_0-auc:0.801348	validation_1-auc:0.646895
[65]	validation_0-auc:0.802434	validation_1-auc:0.649556
[66]	validation_0-auc:0.804187	validation_1-auc:0.650842
[67]	validation_0-auc:0.807223	validation_1-auc:0.650437
[68]	validation_0-auc:0.808216	validation_1-auc:0.650871
[69]	validation_0-auc:0.808628	validation_1-auc:0.650518
[70]	validation_0-auc:0.811467	validation_1-auc:0.653014
[71]	validation_0-auc:0.811955	validation_1-auc:0.652964
[72]	validation_0-auc:0.814149	validation_1-auc:0.65299
[73]	validation_0-auc:0.815371	validation_1-auc:0.652735
[74]	validation_0-auc:0.817049	validation_1-auc:0.653371
[75]	validation_0-auc:0.819074	validation_1-auc:0.653978
[76]	validation_0-auc:0.821418	validation_1-auc:0.656345
[77]	validation_0-auc:0.824515	validation_1-auc:0.654713
[78]	validation_0-auc:0.825047	validation_1-auc:0.655603
[79]	validation_0-auc:0.826575	validation_1-auc:0.655177
[80]	validation_0-auc:0.828261	validation_1-auc:0.657333
[81]	validation_0-auc:0.828888	validation_1-auc:0.657471
[82]	validation_0-auc:0.830403	validation_1-auc:0.657957
[83]	validation_0-auc:0.832506	validation_1-auc:0.658598
[84]	validation_0-auc:0.833419	validation_1-auc:0.660184
[85]	validation_0-auc:0.834847	validation_1-auc:0.658476
[86]	validation_0-auc:0.835366	validation_1-auc:0.658797
[87]	validation_0-auc:0.836399	validation_1-auc:0.659184
[88]	validation_0-auc:0.836645	validation_1-auc:0.659643
[89]	validation_0-auc:0.839064	validation_1-auc:0.661001
[90]	validation_0-auc:0.840548	validation_1-auc:0.660068
[91]	validation_0-auc:0.840898	validation_1-auc:0.662944
[92]	validation_0-auc:0.842439	validation_1-auc:0.662548
[93]	validation_0-auc:0.844621	validation_1-auc:0.662129
[94]	validation_0-auc:0.845059	validation_1-auc:0.66148
[95]	validation_0-auc:0.846459	validation_1-auc:0.660765
[96]	validation_0-auc:0.848228	validation_1-auc:0.661708
[97]	validation_0-auc:0.84888	validation_1-auc:0.661385
[98]	validation_0-auc:0.849389	validation_1-auc:0.662677
[99]	validation_0-auc:0.85026	validation_1-auc:0.66311
[100]	validation_0-auc:0.850633	validation_1-auc:0.661516
[101]	validation_0-auc:0.851554	validation_1-auc:0.662585
[102]	validation_0-auc:0.852811	validation_1-auc:0.663063
[103]	validation_0-auc:0.853701	validation_1-auc:0.663482
[104]	validation_0-auc:0.854618	validation_1-auc:0.663939
[105]	validation_0-auc:0.855036	validation_1-auc:0.66291
[106]	validation_0-auc:0.855688	validation_1-auc:0.662635
[107]	validation_0-auc:0.857634	validation_1-auc:0.660665
[108]	validation_0-auc:0.858464	validation_1-auc:0.659669
[109]	validation_0-auc:0.85941	validation_1-auc:0.660881
[110]	validation_0-auc:0.860359	validation_1-auc:0.662051
[111]	validation_0-auc:0.860717	validation_1-auc:0.661687
[112]	validation_0-auc:0.861505	validation_1-auc:0.662973
[113]	validation_0-auc:0.86402	validation_1-auc:0.660761
[114]	validation_0-auc:0.86541	validation_1-auc:0.661824
[115]	validation_0-auc:0.86714	validation_1-auc:0.664213
[116]	validation_0-auc:0.869604	validation_1-auc:0.664362
[117]	validation_0-auc:0.871242	validation_1-auc:0.662186
[118]	validation_0-auc:0.871652	validation_1-auc:0.661438
[119]	validation_0-auc:0.872231	validation_1-auc:0.662415
[120]	validation_0-auc:0.872919	validation_1-auc:0.662361
[121]	validation_0-auc:0.87445	validation_1-auc:0.661485
[122]	validation_0-auc:0.87575	validation_1-auc:0.660692
[123]	validation_0-auc:0.876564	validation_1-auc:0.66205
[124]	validation_0-auc:0.877357	validation_1-auc:0.66179
[125]	validation_0-auc:0.878478	validation_1-auc:0.660234
[126]	validation_0-auc:0.878792	validation_1-auc:0.659681
[127]	validation_0-auc:0.879897	validation_1-auc:0.660235
[128]	validation_0-auc:0.880057	validation_1-auc:0.660478
[129]	validation_0-auc:0.880592	validation_1-auc:0.660699
[130]	validation_0-auc:0.882334	validation_1-auc:0.659938
[131]	validation_0-auc:0.8846	validation_1-auc:0.658591
[132]	validation_0-auc:0.885135	validation_1-auc:0.660061
[133]	validation_0-auc:0.885742	validation_1-auc:0.659776
[134]	validation_0-auc:0.886262	validation_1-auc:0.659563
[135]	validation_0-auc:0.886371	validation_1-auc:0.659999
[136]	validation_0-auc:0.887554	validation_1-auc:0.661436
[137]	validation_0-auc:0.88798	validation_1-auc:0.661186
[138]	validation_0-auc:0.888505	validation_1-auc:0.660311
[139]	validation_0-auc:0.889064	validation_1-auc:0.659848
[140]	validation_0-auc:0.890283	validation_1-auc:0.659609
[141]	validation_0-auc:0.890968	validation_1-auc:0.65996
[142]	validation_0-auc:0.891215	validation_1-auc:0.660205
[143]	validation_0-auc:0.891435	validation_1-auc:0.661087
[144]	validation_0-auc:0.891815	validation_1-auc:0.659954
[145]	validation_0-auc:0.891971	validation_1-auc:0.659452
[146]	validation_0-auc:0.893007	validation_1-auc:0.658491
[147]	validation_0-auc:0.893503	validation_1-auc:0.658077
[148]	validation_0-auc:0.893696	validation_1-auc:0.65791
[149]	validation_0-auc:0.894021	validation_1-auc:0.658075
[150]	validation_0-auc:0.895103	validation_1-auc:0.658459
[151]	validation_0-auc:0.896085	validation_1-auc:0.657832
[152]	validation_0-auc:0.896553	validation_1-auc:0.657406
[153]	validation_0-auc:0.897219	validation_1-auc:0.657718
[154]	validation_0-auc:0.898429	validation_1-auc:0.655665
[155]	validation_0-auc:0.898322	validation_1-auc:0.655569
[156]	validation_0-auc:0.898655	validation_1-auc:0.656167
[157]	validation_0-auc:0.898816	validation_1-auc:0.655512
[158]	validation_0-auc:0.899278	validation_1-auc:0.654997
[159]	validation_0-auc:0.899603	validation_1-auc:0.655532
[160]	validation_0-auc:0.899769	validation_1-auc:0.655853
[161]	validation_0-auc:0.900426	validation_1-auc:0.655703
[162]	validation_0-auc:0.900731	validation_1-auc:0.656264
[163]	validation_0-auc:0.901647	validation_1-auc:0.659494
[164]	validation_0-auc:0.901755	validation_1-auc:0.659014
[165]	validation_0-auc:0.902264	validation_1-auc:0.658092
[166]	validation_0-auc:0.903019	validation_1-auc:0.658105
[167]	validation_0-auc:0.903344	validation_1-auc:0.658008
[168]	validation_0-auc:0.903445	validation_1-auc:0.657435
[169]	validation_0-auc:0.903569	validation_1-auc:0.657148
[170]	validation_0-auc:0.904184	validation_1-auc:0.658339
[171]	validation_0-auc:0.905904	validation_1-auc:0.659276
[172]	validation_0-auc:0.906451	validation_1-auc:0.659639
[173]	validation_0-auc:0.907843	validation_1-auc:0.659745
[174]	validation_0-auc:0.907988	validation_1-auc:0.659289
[175]	validation_0-auc:0.908263	validation_1-auc:0.65945
[176]	validation_0-auc:0.908712	validation_1-auc:0.660237
[177]	validation_0-auc:0.909264	validation_1-auc:0.660192
[178]	validation_0-auc:0.909363	validation_1-auc:0.659344
[179]	validation_0-auc:0.909609	validation_1-auc:0.658523
[180]	validation_0-auc:0.909952	validation_1-auc:0.660007
[181]	validation_0-auc:0.91032	validation_1-auc:0.660053
[182]	validation_0-auc:0.91072	validation_1-auc:0.659693
[183]	validation_0-auc:0.911656	validation_1-auc:0.659292
[184]	validation_0-auc:0.912654	validation_1-auc:0.65898
[185]	validation_0-auc:0.913218	validation_1-auc:0.658219
[186]	validation_0-auc:0.91345	validation_1-auc:0.658319
[187]	validation_0-auc:0.913453	validation_1-auc:0.658198
[188]	validation_0-auc:0.913562	validation_1-auc:0.658651
[189]	validation_0-auc:0.914191	validation_1-auc:0.659817
[190]	validation_0-auc:0.914323	validation_1-auc:0.659398
[191]	validation_0-auc:0.915758	validation_1-auc:0.658851
[192]	validation_0-auc:0.916659	validation_1-auc:0.659741
[193]	validation_0-auc:0.91775	validation_1-auc:0.659444
[194]	validation_0-auc:0.918424	validation_1-auc:0.659319
[195]	validation_0-auc:0.919081	validation_1-auc:0.661274
[196]	validation_0-auc:0.919131	validation_1-auc:0.661416
[197]	validation_0-auc:0.920186	validation_1-auc:0.661387
[198]	validation_0-auc:0.920345	validation_1-auc:0.661565
[199]	validation_0-auc:0.92061	validation_1-auc:0.662511
0.664361784805038
-------------------------------------------------------------------------------------------------
Fold 6
[0]	validation_0-auc:0.571634	validation_1-auc:0.619483
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.637964	validation_1-auc:0.669117
[2]	validation_0-auc:0.632497	validation_1-auc:0.641866
[3]	validation_0-auc:0.637964	validation_1-auc:0.669117
[4]	validation_0-auc:0.649663	validation_1-auc:0.660383
[5]	validation_0-auc:0.653602	validation_1-auc:0.666653
[6]	validation_0-auc:0.657561	validation_1-auc:0.669715
[7]	validation_0-auc:0.659242	validation_1-auc:0.667885
[8]	validation_0-auc:0.661976	validation_1-auc:0.671063
[9]	validation_0-auc:0.663382	validation_1-auc:0.671387
[10]	validation_0-auc:0.666348	validation_1-auc:0.669674
[11]	validation_0-auc:0.671364	validation_1-auc:0.671776
[12]	validation_0-auc:0.671592	validation_1-auc:0.668056
[13]	validation_0-auc:0.67236	validation_1-auc:0.665859
[14]	validation_0-auc:0.672846	validation_1-auc:0.66544
[15]	validation_0-auc:0.674528	validation_1-auc:0.667929
[16]	validation_0-auc:0.676457	validation_1-auc:0.669319
[17]	validation_0-auc:0.677159	validation_1-auc:0.670292
[18]	validation_0-auc:0.677101	validation_1-auc:0.67063
[19]	validation_0-auc:0.67737	validation_1-auc:0.671353
[20]	validation_0-auc:0.677437	validation_1-auc:0.671796
[21]	validation_0-auc:0.688536	validation_1-auc:0.674867
[22]	validation_0-auc:0.699659	validation_1-auc:0.679713
[23]	validation_0-auc:0.702637	validation_1-auc:0.678087
[24]	validation_0-auc:0.70536	validation_1-auc:0.679464
[25]	validation_0-auc:0.707297	validation_1-auc:0.67871
[26]	validation_0-auc:0.707883	validation_1-auc:0.676714
[27]	validation_0-auc:0.707308	validation_1-auc:0.677678
[28]	validation_0-auc:0.710895	validation_1-auc:0.676235
[29]	validation_0-auc:0.710838	validation_1-auc:0.680774
[30]	validation_0-auc:0.713784	validation_1-auc:0.678388
[31]	validation_0-auc:0.713377	validation_1-auc:0.681507
[32]	validation_0-auc:0.715215	validation_1-auc:0.682869
[33]	validation_0-auc:0.722097	validation_1-auc:0.685679
[34]	validation_0-auc:0.723507	validation_1-auc:0.688461
[35]	validation_0-auc:0.72621	validation_1-auc:0.69528
[36]	validation_0-auc:0.728205	validation_1-auc:0.700266
[37]	validation_0-auc:0.729504	validation_1-auc:0.699764
[38]	validation_0-auc:0.730513	validation_1-auc:0.703885
[39]	validation_0-auc:0.73339	validation_1-auc:0.703882
[40]	validation_0-auc:0.736602	validation_1-auc:0.706899
[41]	validation_0-auc:0.740039	validation_1-auc:0.709549
[42]	validation_0-auc:0.743807	validation_1-auc:0.705989
[43]	validation_0-auc:0.746965	validation_1-auc:0.707675
[44]	validation_0-auc:0.752097	validation_1-auc:0.708923
[45]	validation_0-auc:0.755257	validation_1-auc:0.71133
[46]	validation_0-auc:0.756166	validation_1-auc:0.714285
[47]	validation_0-auc:0.759675	validation_1-auc:0.719731
[48]	validation_0-auc:0.762504	validation_1-auc:0.71674
[49]	validation_0-auc:0.763927	validation_1-auc:0.716449
[50]	validation_0-auc:0.767771	validation_1-auc:0.716885
[51]	validation_0-auc:0.769531	validation_1-auc:0.718334
[52]	validation_0-auc:0.772213	validation_1-auc:0.720743
[53]	validation_0-auc:0.777454	validation_1-auc:0.719525
[54]	validation_0-auc:0.780295	validation_1-auc:0.718772
[55]	validation_0-auc:0.782143	validation_1-auc:0.718214
[56]	validation_0-auc:0.783889	validation_1-auc:0.72
[57]	validation_0-auc:0.785235	validation_1-auc:0.721912
[58]	validation_0-auc:0.789273	validation_1-auc:0.72665
[59]	validation_0-auc:0.792072	validation_1-auc:0.724616
[60]	validation_0-auc:0.793056	validation_1-auc:0.727183
[61]	validation_0-auc:0.796567	validation_1-auc:0.727736
[62]	validation_0-auc:0.797302	validation_1-auc:0.730013
[63]	validation_0-auc:0.798787	validation_1-auc:0.726869
[64]	validation_0-auc:0.800989	validation_1-auc:0.729779
[65]	validation_0-auc:0.802308	validation_1-auc:0.73093
[66]	validation_0-auc:0.803997	validation_1-auc:0.729865
[67]	validation_0-auc:0.804654	validation_1-auc:0.731471
[68]	validation_0-auc:0.807358	validation_1-auc:0.734563
[69]	validation_0-auc:0.809608	validation_1-auc:0.73772
[70]	validation_0-auc:0.810725	validation_1-auc:0.737508
[71]	validation_0-auc:0.814402	validation_1-auc:0.736731
[72]	validation_0-auc:0.814996	validation_1-auc:0.737783
[73]	validation_0-auc:0.816325	validation_1-auc:0.739016
[74]	validation_0-auc:0.818192	validation_1-auc:0.736779
[75]	validation_0-auc:0.818858	validation_1-auc:0.738035
[76]	validation_0-auc:0.819881	validation_1-auc:0.738536
[77]	validation_0-auc:0.822529	validation_1-auc:0.738403
[78]	validation_0-auc:0.824858	validation_1-auc:0.73836
[79]	validation_0-auc:0.826431	validation_1-auc:0.741015
[80]	validation_0-auc:0.826938	validation_1-auc:0.74189
[81]	validation_0-auc:0.828192	validation_1-auc:0.741544
[82]	validation_0-auc:0.829602	validation_1-auc:0.742166
[83]	validation_0-auc:0.830135	validation_1-auc:0.742028
[84]	validation_0-auc:0.832189	validation_1-auc:0.740759
[85]	validation_0-auc:0.833979	validation_1-auc:0.73894
[86]	validation_0-auc:0.836141	validation_1-auc:0.739154
[87]	validation_0-auc:0.837668	validation_1-auc:0.739626
[88]	validation_0-auc:0.838112	validation_1-auc:0.740165
[89]	validation_0-auc:0.839106	validation_1-auc:0.740416
[90]	validation_0-auc:0.839742	validation_1-auc:0.739436
[91]	validation_0-auc:0.840073	validation_1-auc:0.738584
[92]	validation_0-auc:0.841153	validation_1-auc:0.737714
[93]	validation_0-auc:0.843809	validation_1-auc:0.73727
[94]	validation_0-auc:0.844124	validation_1-auc:0.737108
[95]	validation_0-auc:0.844429	validation_1-auc:0.737426
[96]	validation_0-auc:0.845445	validation_1-auc:0.738297
[97]	validation_0-auc:0.846431	validation_1-auc:0.73882
[98]	validation_0-auc:0.84715	validation_1-auc:0.737837
[99]	validation_0-auc:0.848954	validation_1-auc:0.73995
[100]	validation_0-auc:0.849125	validation_1-auc:0.739599
[101]	validation_0-auc:0.850354	validation_1-auc:0.738943
[102]	validation_0-auc:0.851734	validation_1-auc:0.737098
[103]	validation_0-auc:0.852801	validation_1-auc:0.736327
[104]	validation_0-auc:0.853863	validation_1-auc:0.734914
[105]	validation_0-auc:0.854812	validation_1-auc:0.734446
[106]	validation_0-auc:0.855034	validation_1-auc:0.733611
[107]	validation_0-auc:0.855657	validation_1-auc:0.733946
[108]	validation_0-auc:0.855778	validation_1-auc:0.734254
[109]	validation_0-auc:0.858118	validation_1-auc:0.734016
[110]	validation_0-auc:0.858847	validation_1-auc:0.734431
[111]	validation_0-auc:0.859489	validation_1-auc:0.733894
[112]	validation_0-auc:0.859762	validation_1-auc:0.733785
[113]	validation_0-auc:0.860042	validation_1-auc:0.734276
[114]	validation_0-auc:0.860562	validation_1-auc:0.735393
[115]	validation_0-auc:0.861386	validation_1-auc:0.734808
[116]	validation_0-auc:0.86211	validation_1-auc:0.735646
[117]	validation_0-auc:0.862386	validation_1-auc:0.735859
[118]	validation_0-auc:0.862695	validation_1-auc:0.735936
[119]	validation_0-auc:0.86459	validation_1-auc:0.734889
[120]	validation_0-auc:0.865482	validation_1-auc:0.734895
[121]	validation_0-auc:0.865978	validation_1-auc:0.733205
[122]	validation_0-auc:0.867633	validation_1-auc:0.732482
[123]	validation_0-auc:0.868634	validation_1-auc:0.731072
[124]	validation_0-auc:0.868511	validation_1-auc:0.730668
[125]	validation_0-auc:0.869033	validation_1-auc:0.731233
[126]	validation_0-auc:0.86918	validation_1-auc:0.730758
[127]	validation_0-auc:0.869619	validation_1-auc:0.730306
[128]	validation_0-auc:0.870725	validation_1-auc:0.729963
[129]	validation_0-auc:0.871042	validation_1-auc:0.730437
[130]	validation_0-auc:0.872231	validation_1-auc:0.730387
[131]	validation_0-auc:0.874018	validation_1-auc:0.732726
[132]	validation_0-auc:0.874714	validation_1-auc:0.732152
[133]	validation_0-auc:0.87495	validation_1-auc:0.730729
[134]	validation_0-auc:0.876375	validation_1-auc:0.731451
[135]	validation_0-auc:0.876907	validation_1-auc:0.730927
[136]	validation_0-auc:0.876985	validation_1-auc:0.731092
[137]	validation_0-auc:0.877587	validation_1-auc:0.73095
[138]	validation_0-auc:0.878466	validation_1-auc:0.731147
[139]	validation_0-auc:0.878914	validation_1-auc:0.730413
[140]	validation_0-auc:0.879424	validation_1-auc:0.729653
[141]	validation_0-auc:0.880737	validation_1-auc:0.729081
[142]	validation_0-auc:0.881059	validation_1-auc:0.729044
[143]	validation_0-auc:0.882804	validation_1-auc:0.729513
[144]	validation_0-auc:0.883038	validation_1-auc:0.729409
[145]	validation_0-auc:0.883555	validation_1-auc:0.730069
[146]	validation_0-auc:0.884699	validation_1-auc:0.730508
[147]	validation_0-auc:0.885381	validation_1-auc:0.730818
[148]	validation_0-auc:0.885952	validation_1-auc:0.729956
[149]	validation_0-auc:0.887704	validation_1-auc:0.731381
[150]	validation_0-auc:0.888087	validation_1-auc:0.731833
[151]	validation_0-auc:0.888869	validation_1-auc:0.731515
[152]	validation_0-auc:0.889247	validation_1-auc:0.731903
[153]	validation_0-auc:0.889546	validation_1-auc:0.732382
[154]	validation_0-auc:0.89021	validation_1-auc:0.731332
[155]	validation_0-auc:0.891652	validation_1-auc:0.731698
[156]	validation_0-auc:0.892637	validation_1-auc:0.730321
[157]	validation_0-auc:0.893074	validation_1-auc:0.730298
[158]	validation_0-auc:0.893176	validation_1-auc:0.730361
[159]	validation_0-auc:0.89374	validation_1-auc:0.729602
[160]	validation_0-auc:0.894797	validation_1-auc:0.729228
[161]	validation_0-auc:0.895197	validation_1-auc:0.729266
[162]	validation_0-auc:0.895324	validation_1-auc:0.729574
[163]	validation_0-auc:0.895802	validation_1-auc:0.729055
[164]	validation_0-auc:0.895881	validation_1-auc:0.728883
[165]	validation_0-auc:0.896214	validation_1-auc:0.72792
[166]	validation_0-auc:0.897162	validation_1-auc:0.727305
[167]	validation_0-auc:0.897671	validation_1-auc:0.727461
[168]	validation_0-auc:0.897939	validation_1-auc:0.727954
[169]	validation_0-auc:0.898094	validation_1-auc:0.728333
[170]	validation_0-auc:0.898714	validation_1-auc:0.727564
[171]	validation_0-auc:0.898831	validation_1-auc:0.727095
[172]	validation_0-auc:0.89901	validation_1-auc:0.726248
[173]	validation_0-auc:0.899432	validation_1-auc:0.726084
[174]	validation_0-auc:0.900016	validation_1-auc:0.726127
[175]	validation_0-auc:0.900817	validation_1-auc:0.726125
[176]	validation_0-auc:0.900796	validation_1-auc:0.726328
[177]	validation_0-auc:0.902534	validation_1-auc:0.725932
[178]	validation_0-auc:0.903497	validation_1-auc:0.724691
[179]	validation_0-auc:0.904165	validation_1-auc:0.722545
[180]	validation_0-auc:0.904312	validation_1-auc:0.722483
[181]	validation_0-auc:0.904306	validation_1-auc:0.722343
[182]	validation_0-auc:0.905115	validation_1-auc:0.721933
[183]	validation_0-auc:0.906	validation_1-auc:0.722732
[184]	validation_0-auc:0.906041	validation_1-auc:0.722463
[185]	validation_0-auc:0.90634	validation_1-auc:0.7223
[186]	validation_0-auc:0.906801	validation_1-auc:0.722416
[187]	validation_0-auc:0.907332	validation_1-auc:0.721882
[188]	validation_0-auc:0.908753	validation_1-auc:0.721282
[189]	validation_0-auc:0.908725	validation_1-auc:0.721224
[190]	validation_0-auc:0.909892	validation_1-auc:0.721157
[191]	validation_0-auc:0.909941	validation_1-auc:0.721175
[192]	validation_0-auc:0.909925	validation_1-auc:0.721568
[193]	validation_0-auc:0.910181	validation_1-auc:0.720442
[194]	validation_0-auc:0.910654	validation_1-auc:0.720203
[195]	validation_0-auc:0.910787	validation_1-auc:0.719885
[196]	validation_0-auc:0.910826	validation_1-auc:0.718942
[197]	validation_0-auc:0.91124	validation_1-auc:0.719224
[198]	validation_0-auc:0.911693	validation_1-auc:0.720921
[199]	validation_0-auc:0.911761	validation_1-auc:0.721426
0.7421664210103176
-------------------------------------------------------------------------------------------------
Fold 7
[0]	validation_0-auc:0.580407	validation_1-auc:0.540734
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.580407	validation_1-auc:0.540734
[2]	validation_0-auc:0.580407	validation_1-auc:0.540734
[3]	validation_0-auc:0.641615	validation_1-auc:0.628034
[4]	validation_0-auc:0.641615	validation_1-auc:0.628034
[5]	validation_0-auc:0.644883	validation_1-auc:0.631372
[6]	validation_0-auc:0.645172	validation_1-auc:0.63134
[7]	validation_0-auc:0.653652	validation_1-auc:0.640341
[8]	validation_0-auc:0.656517	validation_1-auc:0.646278
[9]	validation_0-auc:0.657335	validation_1-auc:0.644606
[10]	validation_0-auc:0.661062	validation_1-auc:0.64536
[11]	validation_0-auc:0.661633	validation_1-auc:0.646479
[12]	validation_0-auc:0.661618	validation_1-auc:0.64659
[13]	validation_0-auc:0.665475	validation_1-auc:0.650683
[14]	validation_0-auc:0.666452	validation_1-auc:0.651426
[15]	validation_0-auc:0.667127	validation_1-auc:0.650071
[16]	validation_0-auc:0.667629	validation_1-auc:0.65117
[17]	validation_0-auc:0.668411	validation_1-auc:0.652283
[18]	validation_0-auc:0.671906	validation_1-auc:0.654809
[19]	validation_0-auc:0.672735	validation_1-auc:0.655837
[20]	validation_0-auc:0.676219	validation_1-auc:0.65637
[21]	validation_0-auc:0.677729	validation_1-auc:0.657324
[22]	validation_0-auc:0.693744	validation_1-auc:0.666857
[23]	validation_0-auc:0.694396	validation_1-auc:0.666545
[24]	validation_0-auc:0.695709	validation_1-auc:0.664613
[25]	validation_0-auc:0.696945	validation_1-auc:0.666724
[26]	validation_0-auc:0.699395	validation_1-auc:0.669223
[27]	validation_0-auc:0.700328	validation_1-auc:0.66861
[28]	validation_0-auc:0.701578	validation_1-auc:0.667685
[29]	validation_0-auc:0.708965	validation_1-auc:0.675965
[30]	validation_0-auc:0.710879	validation_1-auc:0.677087
[31]	validation_0-auc:0.713996	validation_1-auc:0.678514
[32]	validation_0-auc:0.714186	validation_1-auc:0.676163
[33]	validation_0-auc:0.719732	validation_1-auc:0.683559
[34]	validation_0-auc:0.72186	validation_1-auc:0.677934
[35]	validation_0-auc:0.725359	validation_1-auc:0.680785
[36]	validation_0-auc:0.727751	validation_1-auc:0.679433
[37]	validation_0-auc:0.732895	validation_1-auc:0.674432
[38]	validation_0-auc:0.735233	validation_1-auc:0.679105
[39]	validation_0-auc:0.736836	validation_1-auc:0.679291
[40]	validation_0-auc:0.741432	validation_1-auc:0.675789
[41]	validation_0-auc:0.742387	validation_1-auc:0.676976
[42]	validation_0-auc:0.745121	validation_1-auc:0.672562
[43]	validation_0-auc:0.748083	validation_1-auc:0.673115
[44]	validation_0-auc:0.750829	validation_1-auc:0.675185
[45]	validation_0-auc:0.753279	validation_1-auc:0.67556
[46]	validation_0-auc:0.757856	validation_1-auc:0.676675
[47]	validation_0-auc:0.761029	validation_1-auc:0.679017
[48]	validation_0-auc:0.764444	validation_1-auc:0.681694
[49]	validation_0-auc:0.766157	validation_1-auc:0.685205
[50]	validation_0-auc:0.769103	validation_1-auc:0.688684
[51]	validation_0-auc:0.771322	validation_1-auc:0.689922
[52]	validation_0-auc:0.774024	validation_1-auc:0.689961
[53]	validation_0-auc:0.776814	validation_1-auc:0.693188
[54]	validation_0-auc:0.780029	validation_1-auc:0.696734
[55]	validation_0-auc:0.782217	validation_1-auc:0.697811
[56]	validation_0-auc:0.784663	validation_1-auc:0.700113
[57]	validation_0-auc:0.787226	validation_1-auc:0.701956
[58]	validation_0-auc:0.790791	validation_1-auc:0.706026
[59]	validation_0-auc:0.791289	validation_1-auc:0.706638
[60]	validation_0-auc:0.794226	validation_1-auc:0.708585
[61]	validation_0-auc:0.79677	validation_1-auc:0.709781
[62]	validation_0-auc:0.797923	validation_1-auc:0.710364
[63]	validation_0-auc:0.798754	validation_1-auc:0.710981
[64]	validation_0-auc:0.799819	validation_1-auc:0.711846
[65]	validation_0-auc:0.801168	validation_1-auc:0.712435
[66]	validation_0-auc:0.803808	validation_1-auc:0.712752
[67]	validation_0-auc:0.804613	validation_1-auc:0.711262
[68]	validation_0-auc:0.805949	validation_1-auc:0.710131
[69]	validation_0-auc:0.807808	validation_1-auc:0.711751
[70]	validation_0-auc:0.809927	validation_1-auc:0.712527
[71]	validation_0-auc:0.809958	validation_1-auc:0.712278
[72]	validation_0-auc:0.815276	validation_1-auc:0.711214
[73]	validation_0-auc:0.816726	validation_1-auc:0.711058
[74]	validation_0-auc:0.819024	validation_1-auc:0.708788
[75]	validation_0-auc:0.820134	validation_1-auc:0.709775
[76]	validation_0-auc:0.821122	validation_1-auc:0.710993
[77]	validation_0-auc:0.822224	validation_1-auc:0.711722
[78]	validation_0-auc:0.824786	validation_1-auc:0.711892
[79]	validation_0-auc:0.825567	validation_1-auc:0.712462
[80]	validation_0-auc:0.826674	validation_1-auc:0.712617
[81]	validation_0-auc:0.828672	validation_1-auc:0.710398
[82]	validation_0-auc:0.829352	validation_1-auc:0.71009
[83]	validation_0-auc:0.830964	validation_1-auc:0.711816
[84]	validation_0-auc:0.831224	validation_1-auc:0.712333
[85]	validation_0-auc:0.832369	validation_1-auc:0.713555
[86]	validation_0-auc:0.832842	validation_1-auc:0.717055
[87]	validation_0-auc:0.833266	validation_1-auc:0.716401
[88]	validation_0-auc:0.834397	validation_1-auc:0.715161
[89]	validation_0-auc:0.835063	validation_1-auc:0.715292
[90]	validation_0-auc:0.836812	validation_1-auc:0.717128
[91]	validation_0-auc:0.837499	validation_1-auc:0.716774
[92]	validation_0-auc:0.837746	validation_1-auc:0.716143
[93]	validation_0-auc:0.837763	validation_1-auc:0.716406
[94]	validation_0-auc:0.838916	validation_1-auc:0.715951
[95]	validation_0-auc:0.839768	validation_1-auc:0.714976
[96]	validation_0-auc:0.840289	validation_1-auc:0.714923
[97]	validation_0-auc:0.841814	validation_1-auc:0.715447
[98]	validation_0-auc:0.842493	validation_1-auc:0.714944
[99]	validation_0-auc:0.842882	validation_1-auc:0.715318
[100]	validation_0-auc:0.8454	validation_1-auc:0.715192
[101]	validation_0-auc:0.846912	validation_1-auc:0.715676
[102]	validation_0-auc:0.84772	validation_1-auc:0.717827
[103]	validation_0-auc:0.848066	validation_1-auc:0.716921
[104]	validation_0-auc:0.849453	validation_1-auc:0.717313
[105]	validation_0-auc:0.849721	validation_1-auc:0.717134
[106]	validation_0-auc:0.851732	validation_1-auc:0.716444
[107]	validation_0-auc:0.852467	validation_1-auc:0.716823
[108]	validation_0-auc:0.853562	validation_1-auc:0.715825
[109]	validation_0-auc:0.853709	validation_1-auc:0.715723
[110]	validation_0-auc:0.854297	validation_1-auc:0.715989
[111]	validation_0-auc:0.85637	validation_1-auc:0.715782
[112]	validation_0-auc:0.856995	validation_1-auc:0.714863
[113]	validation_0-auc:0.857254	validation_1-auc:0.715294
[114]	validation_0-auc:0.857649	validation_1-auc:0.715146
[115]	validation_0-auc:0.858795	validation_1-auc:0.71513
[116]	validation_0-auc:0.860036	validation_1-auc:0.715478
[117]	validation_0-auc:0.860581	validation_1-auc:0.713842
[118]	validation_0-auc:0.86091	validation_1-auc:0.712859
[119]	validation_0-auc:0.861233	validation_1-auc:0.711868
[120]	validation_0-auc:0.861798	validation_1-auc:0.711038
[121]	validation_0-auc:0.863073	validation_1-auc:0.712415
[122]	validation_0-auc:0.863321	validation_1-auc:0.712122
[123]	validation_0-auc:0.863434	validation_1-auc:0.712503
[124]	validation_0-auc:0.863823	validation_1-auc:0.71319
[125]	validation_0-auc:0.865779	validation_1-auc:0.712267
[126]	validation_0-auc:0.866528	validation_1-auc:0.711449
[127]	validation_0-auc:0.866647	validation_1-auc:0.711111
[128]	validation_0-auc:0.868023	validation_1-auc:0.711324
[129]	validation_0-auc:0.868306	validation_1-auc:0.712708
[130]	validation_0-auc:0.869439	validation_1-auc:0.712615
[131]	validation_0-auc:0.87064	validation_1-auc:0.713681
[132]	validation_0-auc:0.872827	validation_1-auc:0.712446
[133]	validation_0-auc:0.873156	validation_1-auc:0.712636
[134]	validation_0-auc:0.874452	validation_1-auc:0.711984
[135]	validation_0-auc:0.874635	validation_1-auc:0.71155
[136]	validation_0-auc:0.875151	validation_1-auc:0.711528
[137]	validation_0-auc:0.876732	validation_1-auc:0.713302
[138]	validation_0-auc:0.877449	validation_1-auc:0.714031
[139]	validation_0-auc:0.878375	validation_1-auc:0.714339
[140]	validation_0-auc:0.879657	validation_1-auc:0.712699
[141]	validation_0-auc:0.879853	validation_1-auc:0.71173
[142]	validation_0-auc:0.880695	validation_1-auc:0.71138
[143]	validation_0-auc:0.880972	validation_1-auc:0.711912
[144]	validation_0-auc:0.881516	validation_1-auc:0.711276
[145]	validation_0-auc:0.882083	validation_1-auc:0.711036
[146]	validation_0-auc:0.882981	validation_1-auc:0.710075
[147]	validation_0-auc:0.883944	validation_1-auc:0.710266
[148]	validation_0-auc:0.885079	validation_1-auc:0.710319
[149]	validation_0-auc:0.886564	validation_1-auc:0.711133
[150]	validation_0-auc:0.886812	validation_1-auc:0.710102
[151]	validation_0-auc:0.887041	validation_1-auc:0.70965
[152]	validation_0-auc:0.887211	validation_1-auc:0.710193
[153]	validation_0-auc:0.88782	validation_1-auc:0.710201
[154]	validation_0-auc:0.8882	validation_1-auc:0.709746
[155]	validation_0-auc:0.890283	validation_1-auc:0.710216
[156]	validation_0-auc:0.890756	validation_1-auc:0.71113
[157]	validation_0-auc:0.891371	validation_1-auc:0.711721
[158]	validation_0-auc:0.891769	validation_1-auc:0.711685
[159]	validation_0-auc:0.892243	validation_1-auc:0.712174
[160]	validation_0-auc:0.892715	validation_1-auc:0.712148
[161]	validation_0-auc:0.892829	validation_1-auc:0.712162
[162]	validation_0-auc:0.893463	validation_1-auc:0.713044
[163]	validation_0-auc:0.893797	validation_1-auc:0.713472
[164]	validation_0-auc:0.894331	validation_1-auc:0.713103
[165]	validation_0-auc:0.894502	validation_1-auc:0.712742
[166]	validation_0-auc:0.895943	validation_1-auc:0.71278
[167]	validation_0-auc:0.897021	validation_1-auc:0.713534
[168]	validation_0-auc:0.898157	validation_1-auc:0.714097
[169]	validation_0-auc:0.898824	validation_1-auc:0.713887
[170]	validation_0-auc:0.89939	validation_1-auc:0.714112
[171]	validation_0-auc:0.901071	validation_1-auc:0.713742
[172]	validation_0-auc:0.902105	validation_1-auc:0.713625
[173]	validation_0-auc:0.902243	validation_1-auc:0.71349
[174]	validation_0-auc:0.903164	validation_1-auc:0.712426
[175]	validation_0-auc:0.903636	validation_1-auc:0.712578
[176]	validation_0-auc:0.90408	validation_1-auc:0.712482
[177]	validation_0-auc:0.905743	validation_1-auc:0.711688
[178]	validation_0-auc:0.907738	validation_1-auc:0.709882
[179]	validation_0-auc:0.909004	validation_1-auc:0.708342
[180]	validation_0-auc:0.909306	validation_1-auc:0.708158
[181]	validation_0-auc:0.909379	validation_1-auc:0.707751
[182]	validation_0-auc:0.910224	validation_1-auc:0.708096
[183]	validation_0-auc:0.910193	validation_1-auc:0.707991
[184]	validation_0-auc:0.910742	validation_1-auc:0.709005
[185]	validation_0-auc:0.911065	validation_1-auc:0.709083
[186]	validation_0-auc:0.91126	validation_1-auc:0.708737
[187]	validation_0-auc:0.911634	validation_1-auc:0.708608
[188]	validation_0-auc:0.911934	validation_1-auc:0.708481
[189]	validation_0-auc:0.912135	validation_1-auc:0.708206
[190]	validation_0-auc:0.912563	validation_1-auc:0.709506
[191]	validation_0-auc:0.91284	validation_1-auc:0.710678
[192]	validation_0-auc:0.913563	validation_1-auc:0.710992
[193]	validation_0-auc:0.91407	validation_1-auc:0.711226
[194]	validation_0-auc:0.915096	validation_1-auc:0.711237
[195]	validation_0-auc:0.915615	validation_1-auc:0.710902
[196]	validation_0-auc:0.917047	validation_1-auc:0.711774
[197]	validation_0-auc:0.917208	validation_1-auc:0.712367
[198]	validation_0-auc:0.918315	validation_1-auc:0.712307
[199]	validation_0-auc:0.918808	validation_1-auc:0.714782
0.717827147259815
-------------------------------------------------------------------------------------------------
Fold 8
[0]	validation_0-auc:0.573784	validation_1-auc:0.600516
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.640544	validation_1-auc:0.646376
[2]	validation_0-auc:0.640544	validation_1-auc:0.646376
[3]	validation_0-auc:0.657139	validation_1-auc:0.645775
[4]	validation_0-auc:0.659744	validation_1-auc:0.645038
[5]	validation_0-auc:0.66013	validation_1-auc:0.645144
[6]	validation_0-auc:0.666786	validation_1-auc:0.647817
[7]	validation_0-auc:0.668864	validation_1-auc:0.64815
[8]	validation_0-auc:0.669476	validation_1-auc:0.647483
[9]	validation_0-auc:0.669964	validation_1-auc:0.64738
[10]	validation_0-auc:0.672273	validation_1-auc:0.643877
[11]	validation_0-auc:0.673775	validation_1-auc:0.647803
[12]	validation_0-auc:0.674092	validation_1-auc:0.644439
[13]	validation_0-auc:0.674389	validation_1-auc:0.643612
[14]	validation_0-auc:0.674462	validation_1-auc:0.643718
[15]	validation_0-auc:0.677045	validation_1-auc:0.648082
[16]	validation_0-auc:0.689725	validation_1-auc:0.637944
[17]	validation_0-auc:0.689932	validation_1-auc:0.637419
[18]	validation_0-auc:0.690776	validation_1-auc:0.637239
[19]	validation_0-auc:0.692946	validation_1-auc:0.63696
[20]	validation_0-auc:0.697512	validation_1-auc:0.638007
[21]	validation_0-auc:0.69928	validation_1-auc:0.634155
[22]	validation_0-auc:0.699913	validation_1-auc:0.635766
[23]	validation_0-auc:0.702049	validation_1-auc:0.636173
[24]	validation_0-auc:0.70295	validation_1-auc:0.637098
[25]	validation_0-auc:0.710403	validation_1-auc:0.634412
[26]	validation_0-auc:0.71263	validation_1-auc:0.63571
[27]	validation_0-auc:0.713691	validation_1-auc:0.634791
[28]	validation_0-auc:0.717053	validation_1-auc:0.6372
[29]	validation_0-auc:0.718428	validation_1-auc:0.636255
[30]	validation_0-auc:0.718998	validation_1-auc:0.635605
[31]	validation_0-auc:0.721887	validation_1-auc:0.635871
[32]	validation_0-auc:0.722333	validation_1-auc:0.63483
[33]	validation_0-auc:0.724208	validation_1-auc:0.637296
[34]	validation_0-auc:0.728015	validation_1-auc:0.641441
[35]	validation_0-auc:0.731079	validation_1-auc:0.642449
[36]	validation_0-auc:0.733497	validation_1-auc:0.644423
[37]	validation_0-auc:0.735033	validation_1-auc:0.645801
[38]	validation_0-auc:0.738819	validation_1-auc:0.650189
[39]	validation_0-auc:0.741195	validation_1-auc:0.649271
[40]	validation_0-auc:0.745039	validation_1-auc:0.64994
[41]	validation_0-auc:0.748924	validation_1-auc:0.648951
[42]	validation_0-auc:0.751307	validation_1-auc:0.651797
[43]	validation_0-auc:0.754081	validation_1-auc:0.648889
[44]	validation_0-auc:0.755314	validation_1-auc:0.649816
[45]	validation_0-auc:0.758059	validation_1-auc:0.650485
[46]	validation_0-auc:0.760767	validation_1-auc:0.653842
[47]	validation_0-auc:0.763347	validation_1-auc:0.652314
[48]	validation_0-auc:0.764163	validation_1-auc:0.654043
[49]	validation_0-auc:0.76644	validation_1-auc:0.653417
[50]	validation_0-auc:0.768745	validation_1-auc:0.656603
[51]	validation_0-auc:0.771242	validation_1-auc:0.655745
[52]	validation_0-auc:0.772661	validation_1-auc:0.657878
[53]	validation_0-auc:0.775742	validation_1-auc:0.658886
[54]	validation_0-auc:0.777648	validation_1-auc:0.660289
[55]	validation_0-auc:0.781622	validation_1-auc:0.665431
[56]	validation_0-auc:0.784696	validation_1-auc:0.669522
[57]	validation_0-auc:0.786573	validation_1-auc:0.66796
[58]	validation_0-auc:0.789831	validation_1-auc:0.666301
[59]	validation_0-auc:0.791768	validation_1-auc:0.666259
[60]	validation_0-auc:0.794108	validation_1-auc:0.666749
[61]	validation_0-auc:0.796777	validation_1-auc:0.671107
[62]	validation_0-auc:0.797016	validation_1-auc:0.674254
[63]	validation_0-auc:0.799555	validation_1-auc:0.676223
[64]	validation_0-auc:0.801419	validation_1-auc:0.676064
[65]	validation_0-auc:0.804383	validation_1-auc:0.676898
[66]	validation_0-auc:0.807433	validation_1-auc:0.678443
[67]	validation_0-auc:0.808244	validation_1-auc:0.679241
[68]	validation_0-auc:0.809608	validation_1-auc:0.677526
[69]	validation_0-auc:0.812189	validation_1-auc:0.681314
[70]	validation_0-auc:0.813968	validation_1-auc:0.682156
[71]	validation_0-auc:0.815506	validation_1-auc:0.682542
[72]	validation_0-auc:0.818055	validation_1-auc:0.682666
[73]	validation_0-auc:0.818965	validation_1-auc:0.681927
[74]	validation_0-auc:0.820763	validation_1-auc:0.68486
[75]	validation_0-auc:0.82192	validation_1-auc:0.685379
[76]	validation_0-auc:0.823203	validation_1-auc:0.687404
[77]	validation_0-auc:0.823973	validation_1-auc:0.689034
[78]	validation_0-auc:0.826391	validation_1-auc:0.686947
[79]	validation_0-auc:0.827332	validation_1-auc:0.687448
[80]	validation_0-auc:0.829379	validation_1-auc:0.687377
[81]	validation_0-auc:0.830518	validation_1-auc:0.687943
[82]	validation_0-auc:0.831324	validation_1-auc:0.688741
[83]	validation_0-auc:0.832504	validation_1-auc:0.689442
[84]	validation_0-auc:0.834096	validation_1-auc:0.689105
[85]	validation_0-auc:0.834406	validation_1-auc:0.690612
[86]	validation_0-auc:0.835381	validation_1-auc:0.691552
[87]	validation_0-auc:0.836223	validation_1-auc:0.691273
[88]	validation_0-auc:0.837692	validation_1-auc:0.691394
[89]	validation_0-auc:0.838334	validation_1-auc:0.691629
[90]	validation_0-auc:0.838479	validation_1-auc:0.691211
[91]	validation_0-auc:0.839947	validation_1-auc:0.690046
[92]	validation_0-auc:0.840838	validation_1-auc:0.690678
[93]	validation_0-auc:0.841054	validation_1-auc:0.690694
[94]	validation_0-auc:0.842169	validation_1-auc:0.691588
[95]	validation_0-auc:0.84416	validation_1-auc:0.691192
[96]	validation_0-auc:0.844848	validation_1-auc:0.691022
[97]	validation_0-auc:0.845516	validation_1-auc:0.690556
[98]	validation_0-auc:0.84578	validation_1-auc:0.690298
[99]	validation_0-auc:0.846092	validation_1-auc:0.689541
[100]	validation_0-auc:0.846961	validation_1-auc:0.691677
[101]	validation_0-auc:0.847712	validation_1-auc:0.692421
[102]	validation_0-auc:0.849623	validation_1-auc:0.693597
[103]	validation_0-auc:0.849895	validation_1-auc:0.693722
[104]	validation_0-auc:0.850649	validation_1-auc:0.693729
[105]	validation_0-auc:0.851065	validation_1-auc:0.694134
[106]	validation_0-auc:0.851631	validation_1-auc:0.694254
[107]	validation_0-auc:0.852563	validation_1-auc:0.692629
[108]	validation_0-auc:0.853863	validation_1-auc:0.693494
[109]	validation_0-auc:0.855115	validation_1-auc:0.693488
[110]	validation_0-auc:0.855396	validation_1-auc:0.693777
[111]	validation_0-auc:0.855784	validation_1-auc:0.693878
[112]	validation_0-auc:0.856067	validation_1-auc:0.693509
[113]	validation_0-auc:0.856742	validation_1-auc:0.694328
[114]	validation_0-auc:0.857124	validation_1-auc:0.693556
[115]	validation_0-auc:0.858163	validation_1-auc:0.693405
[116]	validation_0-auc:0.8592	validation_1-auc:0.693644
[117]	validation_0-auc:0.860428	validation_1-auc:0.694041
[118]	validation_0-auc:0.860617	validation_1-auc:0.693466
[119]	validation_0-auc:0.862006	validation_1-auc:0.694605
[120]	validation_0-auc:0.862352	validation_1-auc:0.694841
[121]	validation_0-auc:0.862763	validation_1-auc:0.693059
[122]	validation_0-auc:0.864083	validation_1-auc:0.694743
[123]	validation_0-auc:0.864173	validation_1-auc:0.694192
[124]	validation_0-auc:0.865946	validation_1-auc:0.694866
[125]	validation_0-auc:0.866195	validation_1-auc:0.694618
[126]	validation_0-auc:0.866646	validation_1-auc:0.694229
[127]	validation_0-auc:0.867612	validation_1-auc:0.69324
[128]	validation_0-auc:0.868118	validation_1-auc:0.694463
[129]	validation_0-auc:0.868117	validation_1-auc:0.694609
[130]	validation_0-auc:0.86996	validation_1-auc:0.695856
[131]	validation_0-auc:0.87104	validation_1-auc:0.697229
[132]	validation_0-auc:0.872427	validation_1-auc:0.695849
[133]	validation_0-auc:0.873407	validation_1-auc:0.694865
[134]	validation_0-auc:0.873684	validation_1-auc:0.695569
[135]	validation_0-auc:0.875316	validation_1-auc:0.694847
[136]	validation_0-auc:0.876003	validation_1-auc:0.694038
[137]	validation_0-auc:0.876791	validation_1-auc:0.69383
[138]	validation_0-auc:0.876893	validation_1-auc:0.694
[139]	validation_0-auc:0.877356	validation_1-auc:0.694364
[140]	validation_0-auc:0.878583	validation_1-auc:0.693723
[141]	validation_0-auc:0.879531	validation_1-auc:0.692586
[142]	validation_0-auc:0.880476	validation_1-auc:0.693933
[143]	validation_0-auc:0.881573	validation_1-auc:0.694413
[144]	validation_0-auc:0.881879	validation_1-auc:0.695223
[145]	validation_0-auc:0.882162	validation_1-auc:0.695147
[146]	validation_0-auc:0.883594	validation_1-auc:0.695484
[147]	validation_0-auc:0.883912	validation_1-auc:0.695124
[148]	validation_0-auc:0.884929	validation_1-auc:0.695009
[149]	validation_0-auc:0.885474	validation_1-auc:0.694863
[150]	validation_0-auc:0.88693	validation_1-auc:0.695639
[151]	validation_0-auc:0.888508	validation_1-auc:0.694964
[152]	validation_0-auc:0.889585	validation_1-auc:0.693813
[153]	validation_0-auc:0.890152	validation_1-auc:0.693512
[154]	validation_0-auc:0.891114	validation_1-auc:0.693279
[155]	validation_0-auc:0.892193	validation_1-auc:0.693905
[156]	validation_0-auc:0.892449	validation_1-auc:0.693394
[157]	validation_0-auc:0.892639	validation_1-auc:0.69289
[158]	validation_0-auc:0.89263	validation_1-auc:0.693627
[159]	validation_0-auc:0.893801	validation_1-auc:0.693932
[160]	validation_0-auc:0.89458	validation_1-auc:0.693479
[161]	validation_0-auc:0.895736	validation_1-auc:0.692903
[162]	validation_0-auc:0.896449	validation_1-auc:0.692517
[163]	validation_0-auc:0.89744	validation_1-auc:0.692694
[164]	validation_0-auc:0.897615	validation_1-auc:0.693115
[165]	validation_0-auc:0.897695	validation_1-auc:0.69274
[166]	validation_0-auc:0.898385	validation_1-auc:0.693236
[167]	validation_0-auc:0.898546	validation_1-auc:0.692713
[168]	validation_0-auc:0.899321	validation_1-auc:0.690526
[169]	validation_0-auc:0.899444	validation_1-auc:0.690847
[170]	validation_0-auc:0.900527	validation_1-auc:0.690799
[171]	validation_0-auc:0.90159	validation_1-auc:0.690476
[172]	validation_0-auc:0.902432	validation_1-auc:0.691859
[173]	validation_0-auc:0.90369	validation_1-auc:0.692422
[174]	validation_0-auc:0.904194	validation_1-auc:0.692357
[175]	validation_0-auc:0.904308	validation_1-auc:0.692483
[176]	validation_0-auc:0.906044	validation_1-auc:0.692161
[177]	validation_0-auc:0.906078	validation_1-auc:0.692535
[178]	validation_0-auc:0.90736	validation_1-auc:0.69196
[179]	validation_0-auc:0.908135	validation_1-auc:0.692175
[180]	validation_0-auc:0.908458	validation_1-auc:0.692031
[181]	validation_0-auc:0.909038	validation_1-auc:0.690811
[182]	validation_0-auc:0.909297	validation_1-auc:0.691165
[183]	validation_0-auc:0.910133	validation_1-auc:0.690898
[184]	validation_0-auc:0.910307	validation_1-auc:0.690519
[185]	validation_0-auc:0.910719	validation_1-auc:0.690295
[186]	validation_0-auc:0.910799	validation_1-auc:0.690539
[187]	validation_0-auc:0.911539	validation_1-auc:0.690253
[188]	validation_0-auc:0.912696	validation_1-auc:0.691767
[189]	validation_0-auc:0.913552	validation_1-auc:0.692537
[190]	validation_0-auc:0.914008	validation_1-auc:0.69125
[191]	validation_0-auc:0.915006	validation_1-auc:0.691899
[192]	validation_0-auc:0.915454	validation_1-auc:0.691949
[193]	validation_0-auc:0.916381	validation_1-auc:0.690867
[194]	validation_0-auc:0.917658	validation_1-auc:0.691998
[195]	validation_0-auc:0.91813	validation_1-auc:0.691926
[196]	validation_0-auc:0.91847	validation_1-auc:0.692387
[197]	validation_0-auc:0.918711	validation_1-auc:0.693506
[198]	validation_0-auc:0.919512	validation_1-auc:0.693319
[199]	validation_0-auc:0.920011	validation_1-auc:0.69394
0.6972285497342445
-------------------------------------------------------------------------------------------------
Fold 9
[0]	validation_0-auc:0.580273	validation_1-auc:0.541494
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.580273	validation_1-auc:0.541494
[2]	validation_0-auc:0.580273	validation_1-auc:0.541494
[3]	validation_0-auc:0.640634	validation_1-auc:0.629278
[4]	validation_0-auc:0.640634	validation_1-auc:0.629278
[5]	validation_0-auc:0.644106	validation_1-auc:0.632711
[6]	validation_0-auc:0.65189	validation_1-auc:0.634312
[7]	validation_0-auc:0.654986	validation_1-auc:0.636819
[8]	validation_0-auc:0.655724	validation_1-auc:0.636736
[9]	validation_0-auc:0.658756	validation_1-auc:0.641329
[10]	validation_0-auc:0.66096	validation_1-auc:0.640129
[11]	validation_0-auc:0.664447	validation_1-auc:0.643984
[12]	validation_0-auc:0.665999	validation_1-auc:0.646548
[13]	validation_0-auc:0.66781	validation_1-auc:0.650112
[14]	validation_0-auc:0.667765	validation_1-auc:0.650258
[15]	validation_0-auc:0.667971	validation_1-auc:0.650099
[16]	validation_0-auc:0.667963	validation_1-auc:0.651155
[17]	validation_0-auc:0.669562	validation_1-auc:0.651458
[18]	validation_0-auc:0.684667	validation_1-auc:0.655953
[19]	validation_0-auc:0.686426	validation_1-auc:0.656511
[20]	validation_0-auc:0.686861	validation_1-auc:0.655917
[21]	validation_0-auc:0.690174	validation_1-auc:0.652571
[22]	validation_0-auc:0.690948	validation_1-auc:0.652152
[23]	validation_0-auc:0.69385	validation_1-auc:0.651401
[24]	validation_0-auc:0.705223	validation_1-auc:0.65812
[25]	validation_0-auc:0.705576	validation_1-auc:0.657333
[26]	validation_0-auc:0.706331	validation_1-auc:0.659862
[27]	validation_0-auc:0.707729	validation_1-auc:0.660005
[28]	validation_0-auc:0.712417	validation_1-auc:0.662986
[29]	validation_0-auc:0.713464	validation_1-auc:0.664568
[30]	validation_0-auc:0.714875	validation_1-auc:0.665121
[31]	validation_0-auc:0.720394	validation_1-auc:0.648264
[32]	validation_0-auc:0.715948	validation_1-auc:0.664938
[33]	validation_0-auc:0.720939	validation_1-auc:0.648933
[34]	validation_0-auc:0.72714	validation_1-auc:0.668569
[35]	validation_0-auc:0.730874	validation_1-auc:0.667637
[36]	validation_0-auc:0.733826	validation_1-auc:0.671045
[37]	validation_0-auc:0.73568	validation_1-auc:0.673243
[38]	validation_0-auc:0.736867	validation_1-auc:0.677464
[39]	validation_0-auc:0.740742	validation_1-auc:0.682999
[40]	validation_0-auc:0.742785	validation_1-auc:0.682544
[41]	validation_0-auc:0.745031	validation_1-auc:0.689569
[42]	validation_0-auc:0.748673	validation_1-auc:0.693379
[43]	validation_0-auc:0.75235	validation_1-auc:0.690449
[44]	validation_0-auc:0.756928	validation_1-auc:0.691109
[45]	validation_0-auc:0.758976	validation_1-auc:0.694393
[46]	validation_0-auc:0.7617	validation_1-auc:0.691918
[47]	validation_0-auc:0.762722	validation_1-auc:0.690047
[48]	validation_0-auc:0.765101	validation_1-auc:0.695563
[49]	validation_0-auc:0.766533	validation_1-auc:0.696361
[50]	validation_0-auc:0.768035	validation_1-auc:0.695504
[51]	validation_0-auc:0.770852	validation_1-auc:0.697772
[52]	validation_0-auc:0.772999	validation_1-auc:0.699871
[53]	validation_0-auc:0.775459	validation_1-auc:0.703071
[54]	validation_0-auc:0.777893	validation_1-auc:0.706864
[55]	validation_0-auc:0.780854	validation_1-auc:0.710231
[56]	validation_0-auc:0.782476	validation_1-auc:0.709777
[57]	validation_0-auc:0.787097	validation_1-auc:0.711624
[58]	validation_0-auc:0.789123	validation_1-auc:0.7139
[59]	validation_0-auc:0.791667	validation_1-auc:0.715573
[60]	validation_0-auc:0.79223	validation_1-auc:0.716195
[61]	validation_0-auc:0.794559	validation_1-auc:0.717671
[62]	validation_0-auc:0.796148	validation_1-auc:0.717241
[63]	validation_0-auc:0.796978	validation_1-auc:0.715818
[64]	validation_0-auc:0.798135	validation_1-auc:0.71721
[65]	validation_0-auc:0.799541	validation_1-auc:0.716465
[66]	validation_0-auc:0.801126	validation_1-auc:0.718037
[67]	validation_0-auc:0.80298	validation_1-auc:0.720886
[68]	validation_0-auc:0.80476	validation_1-auc:0.721081
[69]	validation_0-auc:0.807805	validation_1-auc:0.720019
[70]	validation_0-auc:0.808131	validation_1-auc:0.720872
[71]	validation_0-auc:0.809812	validation_1-auc:0.721194
[72]	validation_0-auc:0.810293	validation_1-auc:0.721475
[73]	validation_0-auc:0.814594	validation_1-auc:0.724739
[74]	validation_0-auc:0.816654	validation_1-auc:0.725586
[75]	validation_0-auc:0.817514	validation_1-auc:0.726942
[76]	validation_0-auc:0.818488	validation_1-auc:0.72816
[77]	validation_0-auc:0.820005	validation_1-auc:0.727752
[78]	validation_0-auc:0.821949	validation_1-auc:0.727937
[79]	validation_0-auc:0.823105	validation_1-auc:0.7288
[80]	validation_0-auc:0.823662	validation_1-auc:0.729183
[81]	validation_0-auc:0.82656	validation_1-auc:0.728884
[82]	validation_0-auc:0.827945	validation_1-auc:0.730509
[83]	validation_0-auc:0.828539	validation_1-auc:0.730373
[84]	validation_0-auc:0.828563	validation_1-auc:0.729522
[85]	validation_0-auc:0.831298	validation_1-auc:0.731137
[86]	validation_0-auc:0.832918	validation_1-auc:0.733651
[87]	validation_0-auc:0.834406	validation_1-auc:0.73574
[88]	validation_0-auc:0.835927	validation_1-auc:0.738317
[89]	validation_0-auc:0.836	validation_1-auc:0.738248
[90]	validation_0-auc:0.836617	validation_1-auc:0.739066
[91]	validation_0-auc:0.836933	validation_1-auc:0.739407
[92]	validation_0-auc:0.83782	validation_1-auc:0.738931
[93]	validation_0-auc:0.839629	validation_1-auc:0.739562
[94]	validation_0-auc:0.841329	validation_1-auc:0.740031
[95]	validation_0-auc:0.841659	validation_1-auc:0.740118
[96]	validation_0-auc:0.843979	validation_1-auc:0.740357
[97]	validation_0-auc:0.844353	validation_1-auc:0.741381
[98]	validation_0-auc:0.844623	validation_1-auc:0.741263
[99]	validation_0-auc:0.845018	validation_1-auc:0.741861
[100]	validation_0-auc:0.846034	validation_1-auc:0.740819
[101]	validation_0-auc:0.846325	validation_1-auc:0.741229
[102]	validation_0-auc:0.847986	validation_1-auc:0.742182
[103]	validation_0-auc:0.848816	validation_1-auc:0.742106
[104]	validation_0-auc:0.850022	validation_1-auc:0.742248
[105]	validation_0-auc:0.850738	validation_1-auc:0.743217
[106]	validation_0-auc:0.851885	validation_1-auc:0.742959
[107]	validation_0-auc:0.852097	validation_1-auc:0.743263
[108]	validation_0-auc:0.853518	validation_1-auc:0.743107
[109]	validation_0-auc:0.854531	validation_1-auc:0.743792
[110]	validation_0-auc:0.856777	validation_1-auc:0.744758
[111]	validation_0-auc:0.857329	validation_1-auc:0.743309
[112]	validation_0-auc:0.858259	validation_1-auc:0.742681
[113]	validation_0-auc:0.858536	validation_1-auc:0.742762
[114]	validation_0-auc:0.860058	validation_1-auc:0.743166
[115]	validation_0-auc:0.860273	validation_1-auc:0.743265
[116]	validation_0-auc:0.861054	validation_1-auc:0.743842
[117]	validation_0-auc:0.862046	validation_1-auc:0.743322
[118]	validation_0-auc:0.862762	validation_1-auc:0.742469
[119]	validation_0-auc:0.864017	validation_1-auc:0.743932
[120]	validation_0-auc:0.864214	validation_1-auc:0.743921
[121]	validation_0-auc:0.865513	validation_1-auc:0.744162
[122]	validation_0-auc:0.86595	validation_1-auc:0.744968
[123]	validation_0-auc:0.867219	validation_1-auc:0.744107
[124]	validation_0-auc:0.867255	validation_1-auc:0.743789
[125]	validation_0-auc:0.868504	validation_1-auc:0.74466
[126]	validation_0-auc:0.868639	validation_1-auc:0.74473
[127]	validation_0-auc:0.869258	validation_1-auc:0.744884
[128]	validation_0-auc:0.869913	validation_1-auc:0.745264
[129]	validation_0-auc:0.87232	validation_1-auc:0.746673
[130]	validation_0-auc:0.873328	validation_1-auc:0.747019
[131]	validation_0-auc:0.873632	validation_1-auc:0.747252
[132]	validation_0-auc:0.874069	validation_1-auc:0.747242
[133]	validation_0-auc:0.874386	validation_1-auc:0.747495
[134]	validation_0-auc:0.875557	validation_1-auc:0.74762
[135]	validation_0-auc:0.87644	validation_1-auc:0.747834
[136]	validation_0-auc:0.877397	validation_1-auc:0.747901
[137]	validation_0-auc:0.878303	validation_1-auc:0.746981
[138]	validation_0-auc:0.87869	validation_1-auc:0.747308
[139]	validation_0-auc:0.879661	validation_1-auc:0.746615
[140]	validation_0-auc:0.881112	validation_1-auc:0.745847
[141]	validation_0-auc:0.881776	validation_1-auc:0.745276
[142]	validation_0-auc:0.882718	validation_1-auc:0.744703
[143]	validation_0-auc:0.883056	validation_1-auc:0.745017
[144]	validation_0-auc:0.883709	validation_1-auc:0.744774
[145]	validation_0-auc:0.884628	validation_1-auc:0.743735
[146]	validation_0-auc:0.886329	validation_1-auc:0.743364
[147]	validation_0-auc:0.888222	validation_1-auc:0.742638
[148]	validation_0-auc:0.888897	validation_1-auc:0.742189
[149]	validation_0-auc:0.888911	validation_1-auc:0.742773
[150]	validation_0-auc:0.889014	validation_1-auc:0.742535
[151]	validation_0-auc:0.889886	validation_1-auc:0.744336
[152]	validation_0-auc:0.890194	validation_1-auc:0.7442
[153]	validation_0-auc:0.891264	validation_1-auc:0.744414
[154]	validation_0-auc:0.892459	validation_1-auc:0.744583
[155]	validation_0-auc:0.893449	validation_1-auc:0.743071
[156]	validation_0-auc:0.894509	validation_1-auc:0.741637
[157]	validation_0-auc:0.894776	validation_1-auc:0.742968
[158]	validation_0-auc:0.895512	validation_1-auc:0.742568
[159]	validation_0-auc:0.895714	validation_1-auc:0.742594
[160]	validation_0-auc:0.895874	validation_1-auc:0.742939
[161]	validation_0-auc:0.897579	validation_1-auc:0.744013
[162]	validation_0-auc:0.898334	validation_1-auc:0.744823
[163]	validation_0-auc:0.899002	validation_1-auc:0.744707
[164]	validation_0-auc:0.899524	validation_1-auc:0.74483
[165]	validation_0-auc:0.89989	validation_1-auc:0.745339
[166]	validation_0-auc:0.901398	validation_1-auc:0.745836
[167]	validation_0-auc:0.90267	validation_1-auc:0.747242
[168]	validation_0-auc:0.902933	validation_1-auc:0.748303
[169]	validation_0-auc:0.902966	validation_1-auc:0.748353
[170]	validation_0-auc:0.903481	validation_1-auc:0.748618
[171]	validation_0-auc:0.903695	validation_1-auc:0.747865
[172]	validation_0-auc:0.904706	validation_1-auc:0.745624
[173]	validation_0-auc:0.905203	validation_1-auc:0.74545
[174]	validation_0-auc:0.905502	validation_1-auc:0.745137
[175]	validation_0-auc:0.905697	validation_1-auc:0.744786
[176]	validation_0-auc:0.906073	validation_1-auc:0.744396
[177]	validation_0-auc:0.907199	validation_1-auc:0.743966
[178]	validation_0-auc:0.907604	validation_1-auc:0.743807
[179]	validation_0-auc:0.907814	validation_1-auc:0.74374
[180]	validation_0-auc:0.908124	validation_1-auc:0.744077
[181]	validation_0-auc:0.908815	validation_1-auc:0.745001
[182]	validation_0-auc:0.909579	validation_1-auc:0.745214
[183]	validation_0-auc:0.909998	validation_1-auc:0.745875
[184]	validation_0-auc:0.910083	validation_1-auc:0.745567
[185]	validation_0-auc:0.91047	validation_1-auc:0.745203
[186]	validation_0-auc:0.910561	validation_1-auc:0.745275
[187]	validation_0-auc:0.910851	validation_1-auc:0.745112
[188]	validation_0-auc:0.911587	validation_1-auc:0.744687
[189]	validation_0-auc:0.912068	validation_1-auc:0.746251
[190]	validation_0-auc:0.912197	validation_1-auc:0.746079
[191]	validation_0-auc:0.912277	validation_1-auc:0.746145
[192]	validation_0-auc:0.913044	validation_1-auc:0.745816
[193]	validation_0-auc:0.913374	validation_1-auc:0.745252
[194]	validation_0-auc:0.913639	validation_1-auc:0.744916
[195]	validation_0-auc:0.913757	validation_1-auc:0.744291
[196]	validation_0-auc:0.913816	validation_1-auc:0.745424
[197]	validation_0-auc:0.913958	validation_1-auc:0.745521
[198]	validation_0-auc:0.914718	validation_1-auc:0.746392
[199]	validation_0-auc:0.914968	validation_1-auc:0.746439
0.7486180713743357
-------------------------------------------------------------------------------------------------
CV score: 0.72015 

#验证is_New,is_old来源于不同的分布
target=train_pdData['isNew']
qianyi_data=train_df.drop(['isNew'],axis=1)
folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=666)
feature_importance_df = pd.DataFrame()
for fold_, (trn_idx, val_idx) in enumerate(folds.split(qianyi_data.values, target)):
    print("Fold {}".format(fold_))

    trn_data, trn_label = qianyi_data.iloc[trn_idx], target[trn_idx]
    val_data, val_label = qianyi_data.iloc[val_idx], target[val_idx]

    trn_data, val_data = trn_data.values, val_data.values
    trn_label, val_label = trn_label.values, val_label.values
    clf = XGBClassifier(max_depth=4, gamma=0, n_estimators=10, eta=0.03, min_child_weight=1)

    view_list = [(trn_data, trn_label), (val_data, val_label)]
    clf.fit(trn_data, trn_label, eval_set=view_list, eval_metric='auc', early_stopping_rounds=200)

    fold_importance_df = pd.DataFrame()
    fold_importance_df["Feature"] = qianyi_data.columns
    fold_importance_df["importance"] = clf.feature_importances_
    fold_importance_df["fold"] = fold_ + 1
    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)

    cols = (feature_importance_df[["Feature", "importance"]]
            .groupby("Feature")
            .mean()
            .sort_values(by="importance", ascending=False)[:150].index)
    best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]

plt.figure(figsize=(14, 30))
sns.barplot(x="importance", y="Feature", data=best_features.sort_values(by="importance", ascending=False))
plt.title('Features importance (averaged/folds)')
plt.tight_layout()
plt.show()
Fold 0
[0]	validation_0-auc:0.997259	validation_1-auc:0.996654
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.997259	validation_1-auc:0.996654
[2]	validation_0-auc:0.997754	validation_1-auc:0.997069
[3]	validation_0-auc:0.997754	validation_1-auc:0.997069
[4]	validation_0-auc:0.997754	validation_1-auc:0.997069
[5]	validation_0-auc:0.997761	validation_1-auc:0.997069
[6]	validation_0-auc:0.997761	validation_1-auc:0.997069
[7]	validation_0-auc:0.997761	validation_1-auc:0.997069
[8]	validation_0-auc:0.997761	validation_1-auc:0.997069
[9]	validation_0-auc:0.997761	validation_1-auc:0.997069
Fold 1
[0]	validation_0-auc:0.997186	validation_1-auc:0.997077
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.997206	validation_1-auc:0.997143
[2]	validation_0-auc:0.997206	validation_1-auc:0.997143
[3]	validation_0-auc:0.997691	validation_1-auc:0.997622
[4]	validation_0-auc:0.9977	validation_1-auc:0.99762
[5]	validation_0-auc:0.9977	validation_1-auc:0.99762
[6]	validation_0-auc:0.9977	validation_1-auc:0.99762
[7]	validation_0-auc:0.9977	validation_1-auc:0.99762
[8]	validation_0-auc:0.9977	validation_1-auc:0.99762
[9]	validation_0-auc:0.9977	validation_1-auc:0.99762
Fold 2
[0]	validation_0-auc:0.997162	validation_1-auc:0.997448
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.997162	validation_1-auc:0.997447
[2]	validation_0-auc:0.997679	validation_1-auc:0.99772
[3]	validation_0-auc:0.997679	validation_1-auc:0.99772
[4]	validation_0-auc:0.997679	validation_1-auc:0.99772
[5]	validation_0-auc:0.997679	validation_1-auc:0.99772
[6]	validation_0-auc:0.997679	validation_1-auc:0.99772
[7]	validation_0-auc:0.997686	validation_1-auc:0.99773
[8]	validation_0-auc:0.997686	validation_1-auc:0.99773
[9]	validation_0-auc:0.997686	validation_1-auc:0.99773
Fold 3
[0]	validation_0-auc:0.997197	validation_1-auc:0.997137
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.997197	validation_1-auc:0.997137
[2]	validation_0-auc:0.997203	validation_1-auc:0.997137
[3]	validation_0-auc:0.997203	validation_1-auc:0.997137
[4]	validation_0-auc:0.997675	validation_1-auc:0.997762
[5]	validation_0-auc:0.997675	validation_1-auc:0.997762
[6]	validation_0-auc:0.997675	validation_1-auc:0.997762
[7]	validation_0-auc:0.997682	validation_1-auc:0.997769
[8]	validation_0-auc:0.997682	validation_1-auc:0.997769
[9]	validation_0-auc:0.997682	validation_1-auc:0.997769
Fold 4
[0]	validation_0-auc:0.99719	validation_1-auc:0.997196
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.99719	validation_1-auc:0.997196
[2]	validation_0-auc:0.99719	validation_1-auc:0.997196
[3]	validation_0-auc:0.997678	validation_1-auc:0.997675
[4]	validation_0-auc:0.997678	validation_1-auc:0.997675
[5]	validation_0-auc:0.997681	validation_1-auc:0.997707
[6]	validation_0-auc:0.997681	validation_1-auc:0.997707
[7]	validation_0-auc:0.997681	validation_1-auc:0.997707
[8]	validation_0-auc:0.997681	validation_1-auc:0.997707
[9]	validation_0-auc:0.997687	validation_1-auc:0.997723
Fold 5
[0]	validation_0-auc:0.997233	validation_1-auc:0.996658
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.997233	validation_1-auc:0.996658
[2]	validation_0-auc:0.997233	validation_1-auc:0.996658
[3]	validation_0-auc:0.997709	validation_1-auc:0.997268
[4]	validation_0-auc:0.997716	validation_1-auc:0.997301
[5]	validation_0-auc:0.99772	validation_1-auc:0.997337
[6]	validation_0-auc:0.997721	validation_1-auc:0.997339
[7]	validation_0-auc:0.997721	validation_1-auc:0.997339
[8]	validation_0-auc:0.997727	validation_1-auc:0.997356
[9]	validation_0-auc:0.997727	validation_1-auc:0.997356
Fold 6
[0]	validation_0-auc:0.997159	validation_1-auc:0.99748
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.997159	validation_1-auc:0.99748
[2]	validation_0-auc:0.997165	validation_1-auc:0.99748
[3]	validation_0-auc:0.997165	validation_1-auc:0.99748
[4]	validation_0-auc:0.997172	validation_1-auc:0.997481
[5]	validation_0-auc:0.997172	validation_1-auc:0.997481
[6]	validation_0-auc:0.997172	validation_1-auc:0.997481
[7]	validation_0-auc:0.997172	validation_1-auc:0.997481
[8]	validation_0-auc:0.997172	validation_1-auc:0.997481
[9]	validation_0-auc:0.997172	validation_1-auc:0.997481
Fold 7
[0]	validation_0-auc:0.997193	validation_1-auc:0.997057
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.997193	validation_1-auc:0.997057
[2]	validation_0-auc:0.997193	validation_1-auc:0.997057
[3]	validation_0-auc:0.997683	validation_1-auc:0.997547
[4]	validation_0-auc:0.997687	validation_1-auc:0.997582
[5]	validation_0-auc:0.997691	validation_1-auc:0.997617
[6]	validation_0-auc:0.997699	validation_1-auc:0.997618
[7]	validation_0-auc:0.997699	validation_1-auc:0.997618
[8]	validation_0-auc:0.997699	validation_1-auc:0.997618
[9]	validation_0-auc:0.997699	validation_1-auc:0.997618
Fold 8
[0]	validation_0-auc:0.997136	validation_1-auc:0.997673
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.997136	validation_1-auc:0.997673
[2]	validation_0-auc:0.997142	validation_1-auc:0.997673
[3]	validation_0-auc:0.997636	validation_1-auc:0.998108
[4]	validation_0-auc:0.997636	validation_1-auc:0.998108
[5]	validation_0-auc:0.997636	validation_1-auc:0.998108
[6]	validation_0-auc:0.997636	validation_1-auc:0.998108
[7]	validation_0-auc:0.997642	validation_1-auc:0.998119
[8]	validation_0-auc:0.997642	validation_1-auc:0.998119
[9]	validation_0-auc:0.997642	validation_1-auc:0.998119
Fold 9
[0]	validation_0-auc:0.997183	validation_1-auc:0.997265
Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.

Will train until validation_1-auc hasn't improved in 200 rounds.
[1]	validation_0-auc:0.997183	validation_1-auc:0.997265
[2]	validation_0-auc:0.997189	validation_1-auc:0.997265
[3]	validation_0-auc:0.997677	validation_1-auc:0.997744
[4]	validation_0-auc:0.997684	validation_1-auc:0.997752
[5]	validation_0-auc:0.997684	validation_1-auc:0.997752
[6]	validation_0-auc:0.997684	validation_1-auc:0.997752
[7]	validation_0-auc:0.997684	validation_1-auc:0.997752
[8]	validation_0-auc:0.997684	validation_1-auc:0.997752
[9]	validation_0-auc:0.997684	validation_1-auc:0.997752

经过XGB对is_New为信息标注的数据进行分类，（见上方代码），AUC达到0.99，可见二者来自两个完全不同的分布，且分布的差异主要来自于job,bankcard,residentAddr,三个特征。bankcard的缺失信息，job==16，residentAddr>1000000的数据几乎全部来自is_New==0的数据。见下图（红色为is_new==1,绿色为is_New==0）
Image Name

Image Name

Image Name

上述分布的差异很可能造成训练数据时，将决策边界拉偏，例如，将residentAddr的首位提取出来，对其他类别特征进行统计特征的构建后，线上A榜下降0.03，明显的说明了is_New分布的差异造成了正确的决策边界被拉偏。
观察residentAddr特征在is_New==0与is_new==1的分布，可看到存在300000的偏差，联系dist特征，发现is_new==1数据的dist与residentAddr相近，但是is_new==0数据的dist与residentAddr均相差300000左右，在进行了对is_new==0数据上的residentAddr特征的更改（即将非-999的数据处理为residentAddr-300000）后，对比更改前后residentAddr特征在训练集与测试集的分布。（见下图），可观察到更改特征后，residentAddr特征在训练集与测试集的分布一致，可减少由数据的分布差异带来影响。
Image Name

Image Name

但是反馈到线上A榜下降了几个千分点，很迷。
调参
params_test1={'min_child_weight':range(1,3),'max_depth':range(3,5,1)}
params_test2={'scale_pos_weight':[0.3,0.4,0.5]}
params_test3={'subsample': [ 0.7, 0.8, 0.9,1], 'colsample_bytree': [0.7, 0.8, 0.9,1]}
params_test4={'reg_alpha': [0.05, 0.1, 1, 2], 'reg_lambda': [0.05, 0.1, 1, 2]}
params_test5={'learning_rate':[0.01,0.02,0.03,0.04],'n_estimators':range(200,300,30)}           
params_test6={'n_estimators':range(1900,2000,10)}
gsearch1=GridSearchCV(estimator=XGBClassifier(max_depth=3,gamma=0,n_estimators=200,eta=0.03,min_child_weight=1,
subsample=0.7,colsample_bytree=0.7,reg_alpha=0.1, reg_lambda=2)
        ,param_grid=params_test2,scoring='roc_auc',cv=3,n_jobs=-1)
gsearch1.fit(train_df0,target)
print('网格搜索-度量记录：',gsearch1.cv_results_)
print('网格搜索-最佳度量值:',gsearch1.best_score_)
print('网格搜索-最佳参数：',gsearch1.best_params_)
总结
1.certID,dist,bankcard,residentAddr特征编码中存在较多的隐藏信息，比如大区，省，省会等信息。
2.is_New==0,与is_New==1的数据来源于两个完全不同的分布，找到造成差异的主要特征， job,bankcard,residentAddr
3.类别特征中，比如周六的数据的先验概率在is_New==0,与is_New==1上差异很大，还有其他的一些同样存在差异。
4.可以尝试利用迁移学习进行建模。
